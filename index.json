[{"content":"\n\n# Maven私服\n\n## 环境\n\ncentos7\n\nDocker version 18.06.3-ce, build d7080c1\n\n[sonatype/nexus3:3.18.1](https://hub.docker.com/r/sonatype/nexus3/)\n\n## 搭建方式\n\n- 二进制包搭建\n- docker搭建\n\n## docker搭建\n\n- `docker pull sonatype/nexus3:3.18.1`\n\n- `mkdir -p /docker/nexus-data \u0026\u0026 chown -R 200 /docker/nexus-data`\n  创建挂在数据的目录.\n\n- `docker run -d --restart=always --name nexus -p 8081:8081 -v /docker/nexus-data:/nexus-data sonatype/nexus3:3.18.1 `\n  `-d` 后台运行\n\n  `--restart=always` 开机启动\n\n  `--name` docker的container的名字\n\n  `-v` 挂载本地文件系统路径\n\n  `-p` 挂载端口\n\n- 查看默认账号密码\n  查看`cat /docker/nexus-data/admin.password`\n\n- 登录\n\n  ![image-20190914165029614](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNno1OGkzd2I0ajMxaGIwcHE3N2ouanBn?x-oss-process=image/format,png)\n\n- 改密码 `admin/admin`\n  ![image-20190914165153704](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNno1OXg0bnBkajMxaDMwcHh0YzguanBn?x-oss-process=image/format,png)\n\n  ![image-20190914165213522](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNno1YTlmcmloajMwOHcwNzdxM2EuanBn?x-oss-process=image/format,png)\n\n  \n\n## 配置\n\n- 中央仓库代理配置\n  ![image-20190914165635906](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNno1ZXQ4c3A3ajMxaGIwcHV0ZHUuanBn?x-oss-process=image/format,png)\n\n  ![image-20190914165754825](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNno1ZzZmcTFnajMxaGIwbzE0MnYuanBn?x-oss-process=image/format,png)\n\n- 新建自定义的仓库\n  ![image-20190914170041549](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNno1ajJxZXg3ajMxaGIwbzJqdzIuanBn?x-oss-process=image/format,png)\n  ![image-20190914170245839](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNno1bDg0b203ajMxaGIwbzNncHcuanBn?x-oss-process=image/format,png)\n\n  ![image-20190914170600212](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNno1b2xleW43ajMxYXEwY2JhYzYuanBn?x-oss-process=image/format,png)\n\n## 使用\n\n- 对本地 Maven 配置文件 setting.xml 进行配置\n\n  - 设置 server 账户信息每个server元素配置指定的仓库ID和用户信息\n\n    ```xml\n    \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e\n    \u003csettings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\"\n              xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n              xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\"\u003e\n    \n      \u003clocalRepository\u003e${user.home}/.m2/repository\u003c/localRepository\u003e\n    \n      \u003cservers\u003e\n            \u003cserver\u003e\n                \u003cid\u003eprivate-release\u003c/id\u003e\n                \u003cusername\u003eadmin\u003c/username\u003e\n                \u003cpassword\u003eadmin\u003c/password\u003e\n            \u003c/server\u003e\n            \u003cserver\u003e\n                \u003cid\u003eprivate-snapshot\u003c/id\u003e\n                \u003cusername\u003eadmin\u003c/username\u003e\n                \u003cpassword\u003eadmin\u003c/password\u003e\n            \u003c/server\u003e\n        \u003c/servers\u003e\n    \n        \u003cprofiles\u003e\n            \u003cprofile\u003e\n                \u003cid\u003edev\u003c/id\u003e\n                \u003crepositories\u003e\n                    \u003crepository\u003e\n                        \u003cid\u003eprivate-release\u003c/id\u003e\n                        \u003curl\u003ehttp://192.168.9.233:8081/repository/private-release/\u003c/url\u003e                 \n                    \u003c/repository\u003e\n                    \u003crepository\u003e\n                        \u003cid\u003eprivate-snapshot\u003c/id\u003e\n                        \u003curl\u003ehttp://192.168.9.233:8081/repository/private-snapshot/\u003c/url\u003e\n                    \u003c/repository\u003e\n                \u003c/repositories\u003e\n            \u003c/profile\u003e\n        \u003c/profiles\u003e\n    \n        \u003cactiveProfiles\u003e\n            \u003cactiveProfile\u003edev\u003c/activeProfile\u003e\n        \u003c/activeProfiles\u003e\n    \n    \u003c/settings\u003e\n    ```\n\n    \n\n- pom.xml配置\n\n  ```xml\n  \u003cdistributionManagement\u003e\n    \u003crepository\u003e\n      \u003cid\u003eprivate-release\u003c/id\u003e\n      \u003curl\u003ehttp://192.168.9.233:8081/repository/private-release/\u003c/url\u003e\n    \u003c/repository\u003e\n    \u003csnapshotRepository\u003e\n      \u003cid\u003eprivate-snapshot\u003c/id\u003e\n      \u003curl\u003ehttp://192.168.9.233:8081/repository/private-snapshot/\u003c/url\u003e\n    \u003c/snapshotRepository\u003e\n  \u003c/distributionManagement\u003e\n  \n  \u003cbuild\u003e\n    \u003cplugins\u003e\n      \u003cplugin\u003e\n        \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e\n        \u003cartifactId\u003emaven-compiler-plugin\u003c/artifactId\u003e\n        \u003cconfiguration\u003e\n          \u003csource\u003e8\u003c/source\u003e\n          \u003ctarget\u003e8\u003c/target\u003e\n        \u003c/configuration\u003e\n      \u003c/plugin\u003e\n      \u003cplugin\u003e\n        \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e\n        \u003cartifactId\u003emaven-source-plugin\u003c/artifactId\u003e\n        \u003cversion\u003e3.0.0\u003c/version\u003e\n        \u003cexecutions\u003e\n          \u003cexecution\u003e\n            \u003cid\u003eattach-sources\u003c/id\u003e\n            \u003cgoals\u003e\n              \u003cgoal\u003ejar\u003c/goal\u003e\n            \u003c/goals\u003e\n          \u003c/execution\u003e\n        \u003c/executions\u003e\n      \u003c/plugin\u003e\n      \u003cplugin\u003e\n        \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e\n        \u003cartifactId\u003emaven-javadoc-plugin\u003c/artifactId\u003e\n        \u003cversion\u003e3.0.0\u003c/version\u003e\n        \u003cexecutions\u003e\n          \u003cexecution\u003e\n            \u003cid\u003eattach-javadocs\u003c/id\u003e\n            \u003cgoals\u003e\n              \u003cgoal\u003ejar\u003c/goal\u003e\n            \u003c/goals\u003e\n          \u003c/execution\u003e\n        \u003c/executions\u003e\n      \u003c/plugin\u003e\n    \u003c/plugins\u003e\n  \u003c/build\u003e\n  ```\n\n- 在对应项目执行`mvn deploy`\n  这样即可将对应jar包deploy到private-release的私服库中,如下图\n  ![image-20190914174045560](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNno2b3I5eDRxajMxaGIwbzN3Z24uanBn?x-oss-process=image/format,png)\n\n## 备份\n\n只要将挂在的 `/docker/nexus-data` 里面的数据备份即可\n\n## 还原\n\n将备份的 `/data/nexus-data` 数据挂载到 `nexus` 镜像即可,注意版本的镜像环境变量\n\n可以通过 `docker inspect image` 即可查到对应镜像的环境参数\n\n## 资料\n\nhttps://mp.weixin.qq.com/s/VAAuIF_1JeRa-lmoU481Zg\n\n\n","cover":"images/wallhaven-714079.jpg","link":"20190914/suveng.html","preview":"","title":"Maven私服"},{"content":"\n\n# Prometheus使用\n\n## 环境\n\n- 查看上一篇[安装篇](https://blog.csdn.net/qq_37933685/article/details/100602068)\n- MacOS\n- Centos 7\n- [prometheus-2.12.0.linux-amd64.tar.gz](https://github.com/prometheus/prometheus/releases/download/v2.12.0/prometheus-2.12.0.linux-amd64.tar.gz)\n- [grafana-6.3.5-1.x86_64](https://dl.grafana.com/oss/release/grafana-6.3.5-1.x86_64.rpm)\n- [node_exporter-0.18.1.linux-amd64](https://github.com/prometheus/node_exporter/releases)\n- [pushgateway-0.9.1.linux-amd64](https://github.com/prometheus/pushgateway/releases/download/v0.9.1/pushgateway-0.9.1.linux-amd64.tar.gz)\n\n## 命令行入门实例\n\n- CPU使用率计算\n\n  CPU在t1到t2时间段总的使用时间 = `( user2+ nice2+ system2+ idle2+ iowait2+ irq2+ softirq2) - ( user1+ nice1+ system1+ idle1+ iowait1+ irq1+ softirq1)`\n  CPU在t1到t2时间段空闲使用时间 =` (idle2 - idle1)`\n\n  CPU在t1到t2时间段即时利用率 =  `1 - CPU空闲使用时间 / CPU总的使用时间`\n\n  `increase()` 函数:解决counter类型的时间增量\n\n  多核CPU计算\n\n  `sum() `结果求和\n\n  - 获取CPU时间\n  - 获取空闲时间`idle`\n\n获取总的时间\n\n\n\n- 单台机器的CPU总利用率\n\n  ```go\n  1-(sum(increase(node_cpu_seconds_total{instance=\"192.168.9.232:9100\",mode=\"idle\"}[1m]))/sum(increase(node_cpu_seconds_total{instance=\"192.168.9.232:9100\"}[1m])))\n  ```\n\n- by(instance): 区分不同实例\n\n- ```go\n  (1-( sum(increase(node_cpu_seconds_total{mode=\"idle\"}[1m])) by(instance) / sum(increase(node_cpu_seconds_total{}[1m]) ) by(instance) )) * 100\n  ```\n\n- 计算其他CPU状态时间的使用\n\n  - iowait io等待时间\n\n    `\n    sum(increase(node_cpu_seconds_total{mode=\"iowait\"}[1m])) by(instance) / sum(increase(node_cpu_seconds_total{}[1m]) ) by(instance)\n    `\n\n    \n\n  - irq 硬中断 \n\n    `\n    sum(increase(node_cpu_seconds_total{mode=\"irq\"}[1m])) by(instance) / sum(increase(node_cpu_seconds_total{}[1m]) ) by(instance)\n    `\n\n    \n    \n  - soft irq 软中断  \n  \n    `\n  sum(increase(node_cpu_seconds_total{mode=\"softirq\"}[1m])) by(instance) / sum(increase(node_cpu_seconds_total{}[1m]) ) by(instance)\n    `\n\n    \n\n  - steal 虚拟机的分片时间\n\n    `\n    sum(increase(node_cpu_seconds_total{mode=\"steal\"}[1m])) by(instance) / sum(increase(node_cpu_seconds_total{}[1m]) ) by(instance)\n    `\n  \n    \n  \n  - nice 进程分配nice值的时间\n  \n    `\n    sum(increase(node_cpu_seconds_total{mode=\"nice\"}[1m])) by(instance) / sum(increase(node_cpu_seconds_total{}[1m]) ) by(instance)\n    `\n  \n    \n  \n  - idle空闲\n  \n    `\n    sum(increase(node_cpu_seconds_total{mode=\"idle\"}[1m])) by(instance) / sum(increase(node_cpu_seconds_total{}[1m]) ) by(instance)\n    `\n  \n    \n  \n  - user用户态\n  \n    `\n    sum(increase(node_cpu_seconds_total{mode=\"user\"}[1m])) by(instance) / sum(increase(node_cpu_seconds_total{}[1m]) ) by(instance)\n    `\n  \n  - sytem内核态 \n  \n    `sum(increase(node_cpu_seconds_total{mode=\"system\"}[1m])) by(instance) / sum(increase(node_cpu_seconds_total{}[1m]) ) by(instance)\n  \t \t`\n    \n  \n\n\n\n## 命令行扩展使用\n\n- 过滤\n\n  - 标签过滤 `key{label=\"\"}`\n    - 模糊匹配 ` key{label=~\"web.*\"}`\n  - 数值过滤\n    - 四则运算 `key{.} \u003e 400`\n\n- 函数\n\n  - `rate(.[5m])` 搭配counter型数据, 按照设置的一个时间段,取`counter`在这个时间段的增量的平均每秒\n\n     $value = ∆S/∆t$\n\n    - 时间段的取值 要考虑采集数据的程序采集间隔\n\n  - `increase(.[5m]) `搭配`counter`型数据,取一个时间段的增量\n    $value=∆S$ \n\n  - `sum()`加和\n\n    - 结合 `by()`\n\n  - `topk(x,key)` 取最高前x位\n\n    - 不适合 `graph` ;  适用于`console` 查看\n    - 适合瞬时报警\n\n  - `count()` \n\n    - 模糊监控判断\n\n\n\n## 采集数据\n\n### 服务端启动-适用于生产\n\n- Peometheus加载配置文件\n  - 向prometheus进行发信号\n    -  kill -HUP pid\n  - 向prometheus发送HTTP请求\n    -  curl -XPOST http://prometheus.chenlei.com//blog/reload\n\n- 后台运行\n\n  - [使用 `screen` 工具](https://linux.cn/article-8215-1.html) \n\n  - [使用 `daemonize`](https://github.com/bmc/daemonize)\n\n    ```shell\n    \u003e yum install -y kernel-devel \n    \u003e yum groupinstall -y Development tools\n    \u003e git clone https://github.com/bmc/daemonize.git\n    \u003e cd daemonize\n    \u003e ./configure \u0026\u0026 make \u0026\u0026 make install \n    ```\n\n- 启动`prometheus`额外参数\n\n  - --web.listen-address : 监听地址 `0.0.0.0:9090`\n  - --web.read-timeout : 请求链接最大等待时间 `2m`\n  - --web.max-connections: 最大连接数 `10`\n  - --storage.tsdb.retention: 数据保存期限 `90d`\n  - --storage.tsdb.path: 数据保存路径 `/data/prometheus/server/data`\n  - --query.max-concurrency: 最大并发数 `20`\n  - --query.timeout: 查询超时时间 `2m`\n\n- 存储结构\n\n  ```shell\n  server/\n  └── data\n      ├── 01DM9HP1PHHK2BD1MGC7J1C0YC\n      │   ├── chunks\n      │   │   └── 000001\n      │   ├── index\n      │   ├── meta.json\n      │   └── tombstones\n      ├── 01DM9ZDG8QKWTPYZ86K7XW6FKZ\n      │   ├── chunks\n      │   │   └── 000001\n      │   ├── index\n      │   ├── meta.json\n      │   └── tombstones\n      ├── 01DMAM0NM51YSQ4EVRRV46X2E1\n      │   ├── chunks\n      │   │   └── 000001\n      │   ├── index\n      │   ├── meta.json\n      │   └── tombstones\n      ├── 01DMAM0P4CGJWSSA15QPWJGZXF\n      │   ├── chunks\n      │   │   └── 000001\n      │   ├── index\n      │   ├── meta.json\n      │   └── tombstones\n      ├── lock\n      ├── queries.active\n      └── wal\n          ├── 00000011\n          ├── 00000012\n          ├── 00000013\n          ├── 00000014\n          ├── 00000015\n          ├── 00000016\n          ├── 00000017\n          ├── 00000018\n          └── checkpoint.000010\n              └── 00000000\n  ```\n\n- 近期数据保存在`wal/`目录中,防止突然断电或者重启,以用来恢复内存中的数据\n\n### 服务端配置文件写法\n\n```yml\nglobal:\n  scrape_interval:     5s #抓取频率\n  evaluation_interval: 1s \n\n\n\nalerting:\n  alertmanagers:\n  - static_configs:\n    - targets:\n\n\n\nrule_files:\n\nscrape_configs:\t\n\n  - job_name: 'prometheus'\n\n    static_configs:\n    - targets: ['localhost:9090']\n\n  - job_name: '233-node-exporter'\n\n    static_configs:\n    - targets: ['192.168.9.233:9100']\n\n  - job_name: '232-node-exporter'\n\n    static_configs:\n    - targets: ['192.168.9.232:9100']\n\n  - job_name: '239-node-exporter'\n\n    static_configs:\n    - targets: ['192.168.9.239:9200']\n```\n\n\n\n### node_exporter\n\n[github地址](https://github.com/prometheus/node_exporter)\n\n- 采集服务器的指标\n- 有足够多的默认采集项\n- 可以通过启动时,开启或者禁用某些指标\n\n\n\n### pushgateway\n\n- 介绍\n  主动推送数据到`prometheus server`\n\n  可以单独运行在不同节点上,并不要求是监控节点\n\n- 安装\n  - [0.9.1 / 2019-08-01](https://github.com/prometheus/pushgateway/releases/tag/v0.9.1)\n  - 下载地址: [链接](https://github.com/prometheus/pushgateway/releases/download/v0.9.1/pushgateway-0.9.1.linux-amd64.tar.gz)\n  - 解压\n  - 运行\n\n- 自定义采集脚本发送到pushgateway\n\n  - 安装pushgeteway\n\n  - prometheus配置job关联pushgateway\n\n  - 目标主机编写脚本采集数据\n\n  - [定时执行发送metric数据到pushgateway](https://blog.csdn.net/y_z_w123/article/details/79816474)\n\n    ```bash\n    #!/bin/bash\n    instance_name=instance_name\n    \n    label=label\n    value=123\n    \n    echo \"$label $value\" | curl --data-binary @- http://192.168.9.233:9091/metrics/job/test/instance/$instance_name\n    ```\n\n- 缺点\n  - 单点瓶颈\n  - 没有数据过滤\n\n### 自定义exporter\n\n- 开发流程\n  - [官网介绍](https://prometheus.io/docs/instrumenting/writing_exporters/)\n  - web HTTP 服务, 响应外部GET请求\n  - 运行在后台,定期触发抓取本地的监控数据\n  - 响应结果 必须符合prometheus的metrics的格式\n\n- [Java]Spring版exporter\n  \n  - [自定义Metrics：让Prometheus监控你的应用程序（Spring版）](http://ylzheng.com/2018/01/24/use-prometheus-monitor-your-spring-boot-application/)\n  \n  - Go语言开发Prometheus Exporter[示例](https://blog.csdn.net/lisonglisonglisong/article/details/81743555)\n\n\n\n## 界面可视化\n\n### grafana\n\n- 介绍\n  开源数据绘图工具\n\n- 安装\n\n  - [grafana官网](https://grafana.com/)\n  - [官网安装引导](https://grafana.com/grafana/download?platform=linux)\n  - 默认端口: 3000\n\n- 配置\n  - 添加`prometheus`数据源\n\n    ![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNndtdDU4eXN1ajMxaGIwcWkwdnUuanBn?x-oss-process=image/format,png)\n\n  \n\n  - 添加`dashboard`\n    ![image-20190910175959926](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNndtc3RmZmZiajMxaGMwcjJnbm4uanBn?x-oss-process=image/format,png)\n\n  - 建立Dashboard\n\n    - 数据源配置\n      ![image-20190910175917439](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNnVrcmM1cmozajMxaGMwcjI3Y2ouanBn?x-oss-process=image/format,png)\n\n- 图形配置\n\n  - Visualization\n    ![image-20190910175754722](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNnVrcHdpbnR0ajMxaGMwcjI3Y3UuanBn?x-oss-process=image/format,png)\n  - Axes\n    ![image-20190910175814132](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNnVrcThyeXhkajMxaGMwcjI3Y2suanBn?x-oss-process=image/format,png)\n  - Legend\n    ![image-20190910175830342](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNnVrcWoyeGFkajMxaGMwcjIxMHcuanBn?x-oss-process=image/format,png)\n  - Thresholds \u0026 Time Regions\n    ![image-20190910175852153](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNnVrcXdrOHlkajMxaGMwcjIxMG0uanBn?x-oss-process=image/format,png)\n  - Data link\n\n- 通用配置\n  ![image-20190910180031703](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNnVrc21oOWdwajMxaGMwcjJ3bWUuanBn?x-oss-process=image/format,png)\n\n- 告警配置\n    ![image-20190910180042705](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNnVrc3RldHlpajMxaGMwcjJ0ZzMuanBn?x-oss-process=image/format,png)\n\n  \n\n- 备份\n  - 导出json\n  - save as \n- 还原\n  - 导入json/粘贴json\n- 报警功能 \n  报警是 `grafana 4.0` 的新功能\n  - 钉钉告警\n  - pageduty\n\n\n\n## 实践\n\n- 内存使用率\n  - 数据来源\n    node_exporter\n  - 计算公式\n    $value=available/Sum$\n    实际可用内存=free+buffers+cached\n  - 公式实现\n    `((node_memory_MemFree_bytes+node_memory_Buffers_bytes+node_memory_Cached_bytes)/node_memory_MemTotal_bytes)*100`\n\n- 硬盘io监控\n  - 数据来源\n    node_exporter\n  - 计算公式\n    $value=读速度+写速度$\n  - 公式实现\n    函数: predict_linear(), 预测趋势\n    `(rate(node_disk_read_bytes_total[1m])+rate(node_disk_written_bytes_total[1m]))`\n\n- 网络监控\n\n  - 数据来源\n    bash脚本+pushgateway\n\n  - 脚本编写\n    采集内网流量ping延迟和丢包率\n\n    ```bash\n    instance=`hostname -f`\n    #外网联通\n    lostpk=`timeout 5 ping -q -A -s 500 -W 1000 -c 100 baidu.com | grep transmitted | awk '{print $6}'`\n    #时间\n    rrt=`timeout 5 ping -q -A -s 500 -W 1000 -c 100 baidu.com | grep transmitted | awk '{print $10}'`\n    \n    # value只允许数值型\n    value_lostpk=${lostpk%%\\%}\n    value_rrt=${rrt%%ms}\n    \n    # 通过 pushgateway 发送给prometheus\n    echo \"lostpk_$instance : $value_lostpk\"\n    echo \"lostpk_$instance $value_lostpk\" | curl --data-binary @- http://192.168.9.233:9091/metrics/job/network-traffic/instance/$instance\n    \n    echo \"rrt_$instance : $value_rrt\"\n    echo \"rrt_$instance $value_rrt\" | curl --data-binary @- http://192.168.9.233:9091/metrics/job/network-traffic/instance/$instance\n    \n    ```\n\n  - 定时执行\n    [资料](https://blog.csdn.net/y_z_w123/article/details/79816474)\n    定时执行步骤: \n\n    - 安装crontab\n    - 在`/etc/crontab`配置cron运行对应可执行脚本\n\n  - 查看结果\n\n    - 在prometheus查看targets有没有在线,如果没有需要到prometheus配置,记得刷新配置\n      ![image-20190912115039938](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNndsY3JmeDRoajMxaGIwbjYweG8uanBn?x-oss-process=image/format,png)\n    - 查看配置\n\n    ![image-20190912115136770](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNndtcTg4cGtsajMwbDEwOXB3ZjUuanBn?x-oss-process=image/format,png)\n\n    - 看指标,在命令行输入刚刚自定的key应该会有提示出现`lostpk` `rrt`\n      ![image-20190912124023780](https://imgconvert.csdnimg.cn/aHR0cHM6Ly90dmExLnNpbmFpbWcuY24vbGFyZ2UvMDA2eThtTjZneTFnNndtcm1mZHY1ajMwcnkwZTIwdGkuanBn?x-oss-process=image/format,png)\n\n- `ping` 和 `port`监控问题,prometheus不适合\n\n  - 如果在pushgateway到脚本之间 或者 prometheus 到 pushgateway之间出现网络问题, 那么数据就无法采集, 会出现误报情况\n  - 使用`nagios`可以替换这种监控的缺点\n\n  ","cover":"images/wallhaven-714079.jpg","link":"20190912/suveng.html","preview":"","title":"Prometheus使用"},{"content":"\n\n# Prometheus安装\n\n下载地址: https://prometheus.io/download/\n\n现在时间是: 2019.09.07\n\n安装环境: [Linux centos7 minimal](centos.org/download/) 虚拟机; 宿主主机 MacOS; 软件: virtualBox 6.0.10 r132072\n\n选用版本: \n- [prometheus-2.12.0.linux-amd64.tar.gz](https://github.com/prometheus/prometheus/releases/download/v2.12.0/prometheus-2.12.0.linux-amd64.tar.gz)\n- [grafana-6.3.5-1.x86_64](https://dl.grafana.com/oss/release/grafana-6.3.5-1.x86_64.rpm)\n- [node_exporter-0.18.1.linux-amd64](https://github.com/prometheus/node_exporter/releases)\n- [pushgateway-0.9.1.linux-amd64](https://github.com/prometheus/pushgateway/releases/download/v0.9.1/pushgateway-0.9.1.linux-amd64.tar.gz)\n\n\n\n## 二进制包安装\n\n### 1.安装虚拟机\n\n- 下载镜像\n\n- 在virtualbox安装虚拟机\n\n  - [配置网络](https://blog.csdn.net/qq_37933685/article/details/81169794)\n\n  - [更换国内源](https://www.jianshu.com/p/e63903fd09f0) \n\n  - [【CentOS7】yum安装时出现错误[Errno 14] curl#6 - \"Could not resolve host: mirrors.aliyuncs.com; Unknown e的解决办法](https://blog.csdn.net/oschina_41140683/article/details/82426831)\n\n  - [必装类库](https://www.icode9.com/content-3-361221.html)\n  \n    \n\n### 2.配置 以及 安装依赖\n\n- 配置网络使用网络地址转换模式\n\n- 主机名\n  配置主机名可以快速辨识\n\n- 时钟\n  prometheus是个时序数据库,对时间要求极高,所以安装时间同步的工具,设置时区为东八区, Asia/shanghai\n  [资料](https://blog.csdn.net/zonghua521/article/details/78239212)\n\n  ```shell\n  #安装服务\n  \u003e yum install ntp -y\n  #开机启动\n  \u003e systemctl enable ntpd\n  #设置时区\n  \u003e timedatectl set-timezone Asia/Shanghai\n  #查看时区\n  \u003e timedatectl \n  ```\n\n  \n\n### 3.安装prometheus\n\n我是本地加速下载好压缩包上传的,所以要另外配置 Linux上传下载文件的命令 `rz`\n\n[资料](https://blog.51cto.com/oldboy/588592)\n\n```shell\n#上传下载命令\n\u003e yum install lrzsz -y\n#下载\n\u003e wget https://github.com/prometheus/prometheus/releases/download/v2.12.0/prometheus-2.12.0.linux-amd64.tar.gz\n#解压\n\u003e tar -zxvf prometheus-2.12.0.linux-amd64.tar.gz\n# 配置环境变量\n\u003e vi /etc/profile\n# 加入以下\n# 设置prometheus的环境变量\nPATH=$PATH\nPATH=$PATH:/root/prometheus/server/prometheus-2.12.0.linux-amd64\nexport PATH\n....\n\u003e source /etc/profile\n\n# 启动promethus\n\u003e promethus \n```\n\n### 4.测试联通性\n\n看看输入对应ip:9090能否进入.\n\n如果不能,检查 ping网络状态, telnet端口是否开启\n\n```shell\n# 停止防火墙\n\u003e systemctl stop firewalld\n# 关闭开机启动防火墙\n\u003e systemctl disable firewalld\n# 关闭安全策略\n\u003e vi /etc/sysconfig/selinux\n\n# This file controls the state of SELinux on the system.\n# SELINUX= can take one of these three values:\n#     enforcing - SELinux security policy is enforced.\n#     permissive - SELinux prints warnings instead of enforcing.\n#     disabled - No SELinux policy is loaded.\n# 这里修改为disabled\nSELINUX=disabled\n# SELINUXTYPE= can take one of three values:\n#     targeted - Targeted processes are protected,\n#     minimum - Modification of targeted policy. Only selected processes are protected.\n#     mls - Multi Level Security protection.\nSELINUXTYPE=targeted\n```\n\n[centos7关闭防火墙](https://blog.csdn.net/qq_37933685/article/details/89342051)\n\n### 5.安装成功\n\n![](https://img2018.cnblogs.com/blog/1419387/201909/1419387-20190907160549962-1261486624.png)\n\n\n\n\n## Docker安装\n\n```shell\ndocker run --name prometheus -d -p 127.0.0.1:9090:9090 quay.io/prometheus/prometheus\n```\n\n\n\n## 参考资料\n\n官网: https://prometheus.io/docs/prometheus/latest/getting_started/\n\nhttps://songjiayang.gitbooks.io/prometheus/content/install/binary.html\n\n\n","cover":"images/wallhaven-714079.jpg","link":"20190907/suveng.html","preview":"","title":"Prometheus安装"},{"content":"\n\n# Prometheus 入门与实践\n\n吴 莉, 殷 一鸣, 和 蔡 林\n2018 年 5 月 30 日[发布](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/index.html)\n\n随着容器技术的迅速发展，Kubernetes 已然成为大家追捧的容器集群管理系统。Prometheus 作为生态圈 Cloud Native Computing Foundation（简称：CNCF）中的重要一员,其活跃度仅次于 Kubernetes, 现已广泛用于 Kubernetes 集群的监控系统中。本文将简要介绍 Prometheus 的组成和相关概念，并实例演示 Prometheus 的安装，配置及使用，以便开发人员和云平台运维人员可以快速的掌握 Prometheus。\n\n## Prometheus 简介\n\nPrometheus 是一套开源的系统监控报警框架。它启发于 Google 的 borgmon 监控系统，由工作在 SoundCloud 的 google 前员工在 2012 年创建，作为社区开源项目进行开发，并于 2015 年正式发布。2016 年，Prometheus 正式加入 Cloud Native Computing Foundation，成为受欢迎度仅次于 Kubernetes 的项目。\n\n作为新一代的监控框架，Prometheus 具有以下特点：\n\n- 强大的多维度数据模型：\n  1. 时间序列数据通过 metric 名和键值对来区分。\n  2. 所有的 metrics 都可以设置任意的多维标签。\n  3. 数据模型更随意，不需要刻意设置为以点分隔的字符串。\n  4. 可以对数据模型进行聚合，切割和切片操作。\n  5. 支持双精度浮点类型，标签可以设为全 unicode。\n\n- 灵活而强大的查询语句（PromQL）：在同一个查询语句，可以对多个 metrics 进行乘法、加法、连接、取分数位等操作。\n- 易于管理： Prometheus server 是一个单独的二进制文件，可直接在本地工作，不依赖于分布式存储。\n- 高效：平均每个采样点仅占 3.5 bytes，且一个 Prometheus server 可以处理数百万的 metrics。\n- 使用 pull 模式采集时间序列数据，这样不仅有利于本机测试而且可以避免有问题的服务器推送坏的 metrics。\n- 可以采用 push gateway 的方式把时间序列数据推送至 Prometheus server 端。\n- 可以通过服务发现或者静态配置去获取监控的 targets。\n- 有多种可视化图形界面。\n- 易于伸缩。\n\n需要指出的是，由于数据采集可能会有丢失，所以 Prometheus 不适用对采集数据要 100% 准确的情形。但如果用于记录时间序列数据，Prometheus 具有很大的查询优势，此外，Prometheus 适用于微服务的体系架构。\n\n## Prometheus 组成及架构\n\nPrometheus 生态圈中包含了多个组件，其中许多组件是可选的：\n\n- **Prometheus Server**: 用于收集和存储时间序列数据。\n- **Client Library**: 客户端库，为需要监控的服务生成相应的 metrics 并暴露给 Prometheus server。当 Prometheus server 来 pull 时，直接返回实时状态的 metrics。\n- **Push Gateway**: 主要用于短期的 jobs。由于这类 jobs 存在时间较短，可能在 Prometheus 来 pull 之前就消失了。为此，这次 jobs 可以直接向 Prometheus server 端推送它们的 metrics。这种方式主要用于服务层面的 metrics，对于机器层面的 metrices，需要使用 node exporter。\n- **Exporters**: 用于暴露已有的第三方服务的 metrics 给 Prometheus。\n- **Alertmanager**: 从 Prometheus server 端接收到 alerts 后，会进行去除重复数据，分组，并路由到对收的接受方式，发出报警。常见的接收方式有：电子邮件，pagerduty，OpsGenie, webhook 等。\n- 一些其他的工具。\n\n图 1 为 Prometheus 官方文档中的架构图：\n\n##### 图 1. Prometheus 架构图\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image001.png)\n\n\n\n从上图可以看出，Prometheus 的主要模块包括：Prometheus server, exporters, Pushgateway, PromQL, Alertmanager 以及图形界面。\n\n其大概的工作流程是：\n\n1. Prometheus server 定期从配置好的 jobs 或者 exporters 中拉 metrics，或者接收来自 Pushgateway 发过来的 metrics，或者从其他的 Prometheus server 中拉 metrics。\n2. Prometheus server 在本地存储收集到的 metrics，并运行已定义好的 alert.rules，记录新的时间序列或者向 Alertmanager 推送警报。\n3. Alertmanager 根据配置文件，对接收到的警报进行处理，发出告警。\n4. 在图形界面中，可视化采集数据。\n\n## Prometheus 相关概念\n\n下面将对 Prometheus 中的数据模型，metric 类型以及 instance 和 job 等概念进行介绍，以便读者在 Prometheus 的配置和使用中可以有一个更好的理解。\n\n**数据模型**\n\nPrometheus 中存储的数据为时间序列，是由 metric 的名字和一系列的标签（键值对）唯一标识的，不同的标签则代表不同的时间序列。\n\n- metric 名字：该名字应该具有语义，一般用于表示 metric 的功能，例如：http_requests_total, 表示 http 请求的总数。其中，metric 名字由 ASCII 字符，数字，下划线，以及冒号组成，且必须满足正则表达式` [a-zA-Z_:][a-zA-Z0-9_:]*`。\n- 标签：使同一个时间序列有了不同维度的识别。例如 http_requests_total{method=\"Get\"} 表示所有 http 请求中的 Get 请求。当 method=\"post\" 时，则为新的一个 metric。标签中的键由 ASCII 字符，数字，以及下划线组成，且必须满足正则表达式 `[a-zA-Z_:][a-zA-Z0-9_:]*`。\n- 样本：实际的时间序列，每个序列包括一个 float64 的值和一个毫秒级的时间戳。\n- 格式：`\u003cmetric name\u003e{\u003clabel name\u003e=\u003clabel value\u003e, …}`，例如：`http_requests_total{method=\"POST\",endpoint=\"/api/tracks\"}`\n\n**四种 Metric 类型**\n\nPrometheus 客户端库主要提供四种主要的 metric 类型：\n\n**Counter**\n\n- 一种累加的 metric，典型的应用如：请求的个数，结束的任务数， 出现的错误数等等。\n\n例如，查询 `http_requests_total{method=\"get\", job=\"Prometheus\", handler=\"query\"}` 返回 8，10 秒后，再次查询，则返回 14。\n\n**Gauge**\n\n- 一种常规的 metric，典型的应用如：温度，运行的 goroutines 的个数。\n- 可以任意加减。\n\n例如：`go_goroutines{instance=\"172.17.0.2\", job=\"Prometheus\"}` 返回值 147，10 秒后返回 124。\n\n**Histogram**\n\n- 可以理解为柱状图，典型的应用如：请求持续时间，响应大小。\n- 可以对观察结果采样，分组及统计。\n\n例如，查询 `http_request_duration_microseconds_sum{job=\"Prometheus\", handler=\"query\"}` 时，返回结果如下：\n\n##### 图 2. Histogram metric 返回结果图\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image002.png)\n\n**Summary**\n\n- 类似于 Histogram, 典型的应用如：请求持续时间，响应大小。\n- 提供观测值的 count 和 sum 功能。\n- 提供百分位的功能，即可以按百分比划分跟踪结果。\n\n**instance 和 jobs**\n\n**instance:** 一个单独 scrape 的目标， 一般对应于一个进程。\n\n**jobs:** 一组同种类型的 instances（主要用于保证可扩展性和可靠性），例如：\n\n##### 清单 1. job 和 instance 的关系\n\n```yml\njob: api-server\n \n    instance 1: 1.2.3.4:5670\n    instance 2: 1.2.3.4:5671\n    instance 3: 5.6.7.8:5670\n    instance 4: 5.6.7.8:5671\n```\n\n当 scrape 目标时，Prometheus 会自动给这个 scrape 的时间序列附加一些标签以便更好的分别，例如： instance，job。\n\n下面以实际的 metric 为例，对上述概念进行说明。\n\n##### 图 3. Metrics 示例\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image003.png)\n\n如上图所示，这三个 metric 的名字都一样，他们仅凭 handler 不同而被标识为不同的 metrics。这类 metrics 只会向上累加，是属于 Counter 类型的 metric，且 metrics 中都含有 instance 和 job 这两个标签。\n\n## Node exporter 安装\n\n为了更好的演示 Prometheus 从配置，到监控，到报警的功能，本实例将引入本机 ubuntu server 的监控。由于 Prometheus 主要用于监控 web 服务，如果需要监控 ubuntu server，则需要在本机上安装 node exporter。 Node exporter 主要用于暴露 metrics 给 Prometheus，其中 metrics 包括：cpu 的负载，内存的使用情况，网络等。\n\n安装 node export 首先需要从 github 中下载最新的 node exporter 包，放在指定的目录并解压安装包，在本实例中，放在 /home/lilly/prom/exporters/ 中。\n\n##### 清单 2. 安装 Node exporter\n\n```shell\n\u003e cd /home/lilly/prom/exporters/\n\u003e wget https://github.com/prometheus/node_exporter/releases/download/v0.14.0/node_exporter-0.14.0.linux-amd64.tar.gz\n\n\u003e tar -xvzf node_exporter-0.14.0.linux-amd64.tar.gz\n```\n\n为了更好的启动和停止 node exporter，可以把 node exporter 转换为一个服务。\n\n##### 清单 3. 配置 node exporter 为服务\n\n```shell\nvim /etc/init/node_exporter.conf\n#Prometheus Node Exporter Upstart script \nstart on startup\nscript\n/home/lilly/prom/exporters/node_exporter/node_exporter\nend script\n```\n\n此时，node exporter 已经是一个服务，可以直接用 service 命令进行启停和查看。\n\n##### 清单 4. 查看 node exporter 状态\n\n```shell\nroot@ubuntu1404-dev:~/alertmanager# service node_exporter start\nnode_exporter start/running, process 11017\nroot@ubuntu1404-dev:~/alertmanager# service node_exporter status\nnode_exporter start/running, process 11017\n此时，node exporter 已经监听在 9100 端口。\nroot@ubuntu1404-dev:~/prom# netstat -anp | grep 9100\ntcp6       0      0 :::9100                 :::*                    LISTEN      155/node_exporter\n```\n\n当 node exporter 启动时，可以通过 curl http://localhost:9100/metrics 或者在浏览器中查看 ubuntu server 里面的 metrics，部分 metrics 信息如下：\n\n##### 清单 5. 验证 node exporter\n\n```shell\nroot@ubuntu1404-dev:~/prom# curl http://localhost:9100/metrics\n……\n# HELP node_cpu Seconds the cpus spent in each mode.\n# TYPE node_cpu counter\nnode_cpu{cpu=\"cpu0\",mode=\"guest\"} 0\nnode_cpu{cpu=\"cpu0\",mode=\"idle\"} 30.02\nnode_cpu{cpu=\"cpu0\",mode=\"iowait\"} 0.5\nnode_cpu{cpu=\"cpu0\",mode=\"irq\"} 0\nnode_cpu{cpu=\"cpu0\",mode=\"nice\"} 0\nnode_cpu{cpu=\"cpu0\",mode=\"softirq\"} 0.34\nnode_cpu{cpu=\"cpu0\",mode=\"steal\"} 0\nnode_cpu{cpu=\"cpu0\",mode=\"system\"} 5.38\nnode_cpu{cpu=\"cpu0\",mode=\"user\"} 11.34\n# HELP node_disk_bytes_read The total number of bytes read successfully.\n# TYPE node_disk_bytes_read counter\nnode_disk_bytes_read{device=\"sda\"} 5.50009856e+08\nnode_disk_bytes_read{device=\"sr0\"} 67584\n# HELP node_disk_bytes_written The total number of bytes written successfully.\n# TYPE node_disk_bytes_written counter\nnode_disk_bytes_written{device=\"sda\"} 2.0160512e+07\nnode_disk_bytes_written{device=\"sr0\"} 0\n# HELP node_disk_io_now The number of I/Os currently in progress.\n# TYPE node_disk_io_now gauge\nnode_disk_io_now{device=\"sda\"} 0\nnode_disk_io_now{device=\"sr0\"} 0\n# HELP node_disk_io_time_ms Total Milliseconds spent doing I/Os.\n# TYPE node_disk_io_time_ms counter\nnode_disk_io_time_ms{device=\"sda\"} 3484\nnode_disk_io_time_ms{device=\"sr0\"} 12\n……\n# HELP node_memory_MemAvailable Memory information field MemAvailable.\n# TYPE node_memory_MemAvailable gauge\nnode_memory_MemAvailable 1.373270016e+09\n# HELP node_memory_MemFree Memory information field MemFree.\n# TYPE node_memory_MemFree gauge\nnode_memory_MemFree 9.2403712e+08\n# HELP node_memory_MemTotal Memory information field MemTotal.\n# TYPE node_memory_MemTotal gauge\nnode_memory_MemTotal 2.098388992e+09\n……\n# HELP node_network_receive_drop Network device statistic receive_drop.\n# TYPE node_network_receive_drop gauge\nnode_network_receive_drop{device=\"docker0\"} 0\nnode_network_receive_drop{device=\"eth0\"} 0\nnode_network_receive_drop{device=\"eth1\"} 0\nnode_network_receive_drop{device=\"lo\"} 0\n```\n\n## Prometheus 安装和配置\n\nPrometheus 可以采用多种方式安装，本文直接用官网的 docker image（prom/prometheus）启动一个 Prometheus server, 并配置相应的静态监控 targets，jobs 和 alert.rules 文件。\n\n启动 Prometheus 容器，并把服务绑定在本机的 9090 端口。命令如下：\n\n##### 清单 6. 安装 Prometheus\n\n```shell\ndocker run -d -p 9090:9090 \\\n            -v $PWD/prometheus.yml:/etc/prometheus/prometheus.yml \\\n            -v $PWD/alert.rules:/etc/prometheus/alert.rules \\\n            --name prometheus \\\n            prom/prometheus \\\n            -config.file=/etc/prometheus/prometheus.yml \\\n            -alertmanager.url=http://10.0.2.15:9093\n```\n\n其中 Prometheus 的配置文件 prometheus.yml 内容为：\n\n##### 清单 7. Prometheus.yml 配置文件\n\n```yml\nglobal:                  # 全局设置，可以被覆盖\n  scrape_interval:     15s # 默认值为 15s，用于设置每次数据收集的间隔\n \n  external_labels:   # 所有时间序列和警告与外部通信时用的外部标签\n    monitor: 'codelab-monitor'\n \nrule_files: # 警告规则设置文件\n  - '/etc/prometheus/alert.rules'\n \n# 用于配置 scrape 的 endpoint  配置需要 scrape 的 targets 以及相应的参数\nscrape_configs: \n  # The job name is added as a label `job=\u003cjob_name\u003e` to any timeseries scraped from this config.\n  - job_name: 'prometheus'  # 一定要全局唯一, 采集 Prometheus 自身的 metrics\n \n    # 覆盖全局的 scrape_interval\n    scrape_interval: 5s\n \n    static_configs:  # 静态目标的配置\n      - targets: ['172.17.0.2:9090']\n \n  - job_name: 'node'  # 一定要全局唯一, 采集本机的 metrics，需要在本机安装 node_exporter\n \n    scrape_interval: 10s\n \n    static_configs:\n      - targets: ['10.0.2.15:9100']  # 本机 node_exporter 的 endpoint\n```\n\nalert 规则文件的内容如下：\n\n##### 清单 8. alert.rules 配置文件\n\n```shell\n# Alert for any instance that is unreachable for \u003e5 minutes.\nALERT InstanceDown   # alert 名字\n  IF up == 0           # 判断条件\n  FOR 5m             # 条件保持 5m 才会发出 alert\n  LABELS { severity = \"critical\" }  # 设置 alert 的标签\n  ANNOTATIONS {             # alert 的其他标签，但不用于标识 alert\n    summary = \"Instance {{ $labels.instance }} down\",\n    description = \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.\",\n  }\n```\n\n当 Prometheus server 起来时，可以在 Prometheus 容器的日志中看到：\n\n##### 清单 9. Prometheus 日志\n\n```shell\ntime=\"2017-09-05T08:18:02Z\" level=info msg=\"Starting prometheus (version=1.7.1, branch=master, \nrevision=3afb3fffa3a29c3de865e1172fb740442e9d0133)\" source=\"main.go:88\" \ntime=\"2017-09-05T08:18:02Z\" level=info msg=\"Build context (go=go1.8.3, user=root@0aa1b7fc430d, date=20170612-\n11:44:05)\" source=\"main.go:89\" \ntime=\"2017-09-05T08:18:02Z\" level=info msg=\"Host details (Linux 3.19.0-75-generic #83~14.04.1-Ubuntu SMP Thu Nov \n10 10:51:40 UTC 2016 x86_64 71984d75e6a1 (none))\" source=\"main.go:90\" \ntime=\"2017-09-05T08:18:02Z\" level=info msg=\"Loading configuration file /etc/prometheus/prometheus.yml\" \nsource=\"main.go:252\" \ntime=\"2017-09-05T08:18:03Z\" level=info msg=\"Loading series map and head chunks...\" source=\"storage.go:428\" \ntime=\"2017-09-05T08:18:03Z\" level=info msg=\"0 series loaded.\" source=\"storage.go:439\" \ntime=\"2017-09-05T08:18:03Z\" level=info msg=\"Starting target manager...\" source=\"targetmanager.go:63\" \ntime=\"2017-09-05T08:18:03Z\" level=info msg=\"Listening on :9090\" source=\"web.go:259\"\n\n```\n\n在浏览器中访问 Prometheus 的主页 [http://localhost:9091](http://localhost:9091/), 可以看到 Prometheus 的信息如下：\n\n##### 图 4. Prometheus 状态信息\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image004.png)\n\n\n\n为了保证 Prometheus 确实从 node exporter 中收集数据，可以在 Graph 页面中搜索 metric 名字，如 node_cpu 并点击 Execute，可以在 console 中看到 metric 如下。\n\n##### 图 5. Prometheus 中 metric 查询结果 console 输出示例\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image005.png)\n\n\n\n其中第一条为来自 node exporter 的 metric，此时 ubuntu server 上 goroutines 的个数为 13。点击 Graph 可以观察 metrics 的历史数据。如下图所示：\n\n##### 图 6. Prometheus 中 metric 查询结果 Graph 输出示例\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image006.png)\n\n\n\n## Alertmanager 安装和配置\n\n当接收到 Prometheus 端发送过来的 alerts 时，Alertmanager 会对 alerts 进行去重复，分组，路由到对应集成的接受端，包括：slack，电子邮件，pagerduty，hitchat，webhook。\n\n在 Alertmanager 的配置文件中，需要进行如下配置：\n\n##### 清单 10. Alermanager 中 config.yml 文件\n\n```yml\nroot@ubuntu1404-dev:~/alertmanager# cat config.yml\nglobal:\n    resolve_timeout: 5m\nroute:\n    receiver: 'default-receiver'\n    group_wait: 30s\n    group_interval: 1m\n    repeat_interval: 1m\n    group_by: ['alertname']\n \n    routes:\n    - match:\n        severity: critical\n      receiver: my-slack\n \nreceivers:\n- name: 'my-slack'\n  slack_configs:\n  - send_resolved: true\n    api_url: https://hooks.slack.com/services/***\n    channel: '#alertmanager-critical'\n    text: \"{{ .CommonAnnotations.description }}\"\n \n \n- name: 'default-receiver'\n  slack_configs:\n  - send_resolved: true\n    api_url: https://hooks.slack.com/services/***\n    channel: '#alertmanager-default'\n    text: \"{{ .CommonAnnotations.description }}\"\n```\n\n创建好 config.yml 文件后，可以直接用 docker 启动一个 Alertmanager 的容器，如下：\n\n##### 清单 11. 安装 Alertmanager\n\n```shell\ndocker run -d -p 9093:9093 \n                 –v /home/lilly/alertmanager/config.yml:/etc/alertmanager/config.yml \\\n                 --name alertmanager \\\n                 prom/alertmanager\n \ndocker ps | grep alert\nd1b7a753a688        prom/alertmanager   \"/bin/alertmanager -c\"   25 hours ago        Up 25 hours         \n0.0.0.0:9093-\u003e9093/tcp   alertmanager\n```\n\n当 Alertmanager 服务起来时，可以通过浏览器访 Alertmanager 的主页 [http://localhost:9093](http://localhost:9093/)，其状态信息如下：\n\n##### 图 7. Alertmanager 状态信息\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image007.png)\n\n\n\n在 alerts 的页面中，我们可以看到从 Prometheus sever 端发过来的 alerts，此外，还可以做 alerts 搜索，分组，静音等操作。\n\n##### 图 8. Alertmanager 报警页面\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image008.png)\n\n\n\n## Prometheus 实例演示\n\n下面将通过一个具体的实例来演示 Prometheus 的使用。在 alert.ruels 中定义了 alert 触发的条件是 up 为 0。下面，手动停止 node exporter 服务。\n\n##### 清单 12. 停止 node exporter 服务\n\n```shell\nroot@ubuntu1404-dev:~/prom# service node_exporter stop\nnode_exporter stop/waiting\nroot@ubuntu1404-dev:~/prom# service node_exporter status\nnode_exporter stop/waiting\n```\n\n此时，Prometheus 中查询 metric up,可以看到此时 up{instance=\"10.0.2.15\",job=\"node\"} 的值为 0，如下所示：\n\n##### 图 9. Metric up 的返回值（停）\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image009.png)\n\n此时，Alerts 页面中显示 InstanceDown，状态为 PENDING。因为 alert 规则中定义需要保持 5 分钟，所以在这之前，alerts 还没有发送至 Alertmanager。\n\n##### 图 10. Alert Pending 界面\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image010.png)\n\n\n\n5 分钟后，状态由 PENDING 变为 FIRING，于此同时，在 Alertmanager 中可以看到有一个 alert。\n\n##### 图 11. Alert Firing 界面\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image011.png)\n\n##### 图 12. Alertmanager 警报界面\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image012.png)\n\n\n\n在 Alertmanager 的配置文件中定义，党 severity 为 critical 的时候，往 Alertmanager-critical channel 中发送警告，且每隔两分钟重复发送。如下图所示。\n\n##### 图 13. Slack 告警界面\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image013.png)\n\n\n\n由上可知，当目标失败时，不仅可以在 Prometheus 的主页上实时的查看目标和 alerts 的状态，还可以使用 Alertmanager 发送警告，以便运维人员尽快解决问题。\n\n当问题解决后，Prometheus 不仅会实时更新 metrics 的状态，Alertmanager 也会在 slack 通知 resolved 的消息。以下演示问题解决后的，Prometheus 的操作。\n\n手动启动 node exporter。首先 metric 在 Graph 中恢复至正常值 1。\n\n##### 图 14. Metric up 的返回值（启）\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image014.png)\n\n\n\ntargets 中现实 node 这个 job 是 up 的状态。\n\n##### 图 15. Targets 界面\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image015.png)\n\n\n\nAlerts 为绿色，显示有 0 个激活态的警告。\n\n##### 图 16. Alers resolved 界面\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image016.png)\n\n\n\n而在 Alertmanager 刚刚的 alert 也被清空，显示 No alerts found。\n\n##### 图 17. Alertmanager resolved 界面\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image017.png)\n\n\n\n在 slack 端，在多次红色 FRING 报警后，也收到了绿色了 RESOLVED 消息。\n\n##### 图 18. Slack resolved 界面\n\n![img](https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/image018.png)\n\n## 总结\n\n本文对 Prometheus 的组成，架构和基本概念进行了介绍，并实例演示了 node exporter, Prometheus 和 Alermanager 的配置和运行。最后，以一个监控的 target 的启停为例，演示 Prometheus 的一系列响应以及如何在 Prometheus 和 Alertmanager 中查看服务，警报和告警的状态。对于 Prometheus 中更高级的使用，如查询函数的使用，更多图形界面的集成，请参考官方文档。\n\n## 参考资源\n\n- Prometheus 概念及详细配置请参阅 [Prometheus 官方文档](https://prometheus.io/docs/introduction/overview/)\n- Node exporter 安装请参考 [node_exporter github 仓库](https://github.com/prometheus/node_exporter)\n- Slack 信息发送请参考 [Incoming Webhooks](https://api.slack.com/incoming-webhooks)","cover":"images/wallhaven-714079.jpg","link":"20190906/suveng.html","preview":"","title":"Prometheus 入门与实践"},{"content":"\n\n# springboot2.X 使用spring-data组件对MongoDB做CURD\n\n## 使用背景\n\n基于快速开发,需求不稳定的情况, 我决定使用MongoDB作为存储数据库,搭配使用spring-data\n\n因为快速开发,使用spring data可以直接在类上建表等其他操作,而且对于复合数据模型,MongoDB可以直接存储\n\n## 代码地址\n\n[gitee](https://gitee.com/suveng/demo/tree/master/chapter.003)\n\n[github](https://github.com/suveng/demo/tree/master/chapter.003)\n\n## 入门普通级别\n\n### 1.引入maven依赖\n\n```xml\n\u003cdependencies\u003e\n        \u003c!--###############时间日期操作################--\u003e\n        \u003cdependency\u003e\n            \u003cgroupId\u003ejoda-time\u003c/groupId\u003e\n            \u003cartifactId\u003ejoda-time\u003c/artifactId\u003e\n        \u003c/dependency\u003e\n\n\n        \u003cdependency\u003e\n            \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e\n            \u003cartifactId\u003espring-boot-starter-data-mongodb\u003c/artifactId\u003e\n        \u003c/dependency\u003e\n\n        \u003cdependency\u003e\n            \u003cgroupId\u003ecn.hutool\u003c/groupId\u003e\n            \u003cartifactId\u003ehutool-all\u003c/artifactId\u003e\n        \u003c/dependency\u003e\n\n        \u003cdependency\u003e\n            \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e\n            \u003cartifactId\u003espring-boot-starter\u003c/artifactId\u003e\n        \u003c/dependency\u003e\n        \u003c!--###############springboot-aop模块################--\u003e\n        \u003cdependency\u003e\n            \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e\n            \u003cartifactId\u003espring-boot-starter-aop\u003c/artifactId\u003e\n        \u003c/dependency\u003e\n        \u003c!--###############test模块################--\u003e\n        \u003cdependency\u003e\n            \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e\n            \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e\n            \u003cscope\u003etest\u003c/scope\u003e\n        \u003c/dependency\u003e\n        \u003c!--###############web模块################--\u003e\n        \u003cdependency\u003e\n            \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e\n            \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e\n        \u003c/dependency\u003e\n\n        \u003c!--###############lombok################--\u003e\n        \u003cdependency\u003e\n            \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e\n            \u003cartifactId\u003elombok\u003c/artifactId\u003e\n        \u003c/dependency\u003e\n\n        \u003c!--fast json--\u003e\n        \u003cdependency\u003e\n            \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e\n            \u003cartifactId\u003efastjson\u003c/artifactId\u003e\n        \u003c/dependency\u003e\n\n        \u003cdependency\u003e\n            \u003cgroupId\u003ecom.google.guava\u003c/groupId\u003e\n            \u003cartifactId\u003eguava\u003c/artifactId\u003e\n        \u003c/dependency\u003e\n\n\u003c/dependencies\u003e\n```\n\n\n\n**基于maven dependencyManagement 版本控制如下:** \n\n\n\n```xml\n    \u003cdependencyManagement\u003e\n        \u003cdependencies\u003e\n            \u003cdependency\u003e\n                \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e\n                \u003cartifactId\u003espring-boot-dependencies\u003c/artifactId\u003e\n                \u003cversion\u003e2.1.2.RELEASE\u003c/version\u003e\n                \u003ctype\u003epom\u003c/type\u003e\n                \u003cscope\u003eimport\u003c/scope\u003e\n            \u003c/dependency\u003e\n\n            \u003c!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --\u003e\n            \u003cdependency\u003e\n                \u003cgroupId\u003emysql\u003c/groupId\u003e\n                \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e\n                \u003cversion\u003e5.1.48\u003c/version\u003e\n            \u003c/dependency\u003e\n\n            \u003cdependency\u003e\n                \u003cgroupId\u003ecn.hutool\u003c/groupId\u003e\n                \u003cartifactId\u003ehutool-all\u003c/artifactId\u003e\n                \u003cversion\u003e4.5.16\u003c/version\u003e\n            \u003c/dependency\u003e\n\n            \u003c!--mybatis--\u003e\n            \u003cdependency\u003e\n                \u003cgroupId\u003eorg.mybatis.spring.boot\u003c/groupId\u003e\n                \u003cartifactId\u003emybatis-spring-boot-starter\u003c/artifactId\u003e\n                \u003cversion\u003e2.0.0\u003c/version\u003e\n            \u003c/dependency\u003e\n\n            \u003c!--fast json--\u003e\n            \u003cdependency\u003e\n                \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e\n                \u003cartifactId\u003efastjson\u003c/artifactId\u003e\n                \u003cversion\u003e1.2.56\u003c/version\u003e\n            \u003c/dependency\u003e\n\n            \u003c!-- druid --\u003e\n            \u003cdependency\u003e\n                \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e\n                \u003cartifactId\u003edruid-spring-boot-starter\u003c/artifactId\u003e\n                \u003cversion\u003e1.1.9\u003c/version\u003e\n            \u003c/dependency\u003e\n\n            \u003cdependency\u003e\n                \u003cgroupId\u003ecom.google.guava\u003c/groupId\u003e\n                \u003cartifactId\u003eguava\u003c/artifactId\u003e\n                \u003cversion\u003e19.0\u003c/version\u003e\n            \u003c/dependency\u003e\n        \u003c/dependencies\u003e\n    \u003c/dependencyManagement\u003e\n\n```\n\n### 2.使用docker启动MongoDB\n\n````\ndocker run --restart=\"always\" \\\n          -d \\\n          --name mongo\\\n          -p 27017:27017\\\n          -v /docker/mongo/data/db:/data/db\\\n          mongo:latest --storageEngine wiredTiger \n````\n\n\n\n### 3.创建Mongo的实体类\n\n- @Document(collection=\"female\")\n\n- 设置id: @Id\n\n- 设置属性\n\n- 构建索引\n\n- getter/setter\n\n\u003e [Female.java](https://github.com/suveng/demo/blob/master/chapter.003/src/main/java/my/suveng/app/model/Female.java) \n\n```\n@Document(collection = \"female\")\n@Data\npublic class Female {\n\t/**\n\t * 主键\n\t */\n\t@Id\n\tprivate String id;\n\n\t/**\n\t * 姓名\n\t */\n\tprivate String name;\n\n\t/**\n\t * 年龄\n\t */\n\tprivate String age;\n\n\t/**\n\t * 哪种类型的女人;FemaleTypeEnums\n\t */\n\tprivate Integer type;\n\n\t/**\n\t * 舔狗\n\t */\n\tprivate List\u003cMale\u003e dogs;\n\n\t/**\n\t * 男朋友们\n\t */\n\t@Indexed\n\tprivate List\u003cMale\u003e boyFriends;\n\n\t/**\n\t * 男神们\n\t */\n\t@Indexed\n\tprivate List\u003cMale\u003e dreamers;\n\n\t/**\n\t * 创建时间\n\t */\n\t@Indexed\n\tprivate Date createTime;\n\n\t/**\n\t * 修改时间\n\t */\n\tprivate Date modifiedTime;\n}\n```\n\n### 4.创建Dao层\n\n- 创建Repository 继承于MongoRepository\n\n- 根据规则来编写接口方法, spring data mongodb的dao 方法规则详细查看[点这里](https://docs.spring.io/spring-data/data-mongodb/docs/2.1.2.RELEASE/reference/html/#repositories.query-methods.details),理论上用idea会提示出来的.\n\n- 编写单元测试方法\n\n\n\n**创建Repository 继承于MongoRepository,编写接口方法**\n\n\u003e [FemaleRepository.java](https://github.com/suveng/demo/blob/master/chapter.003/src/main/java/my/suveng/app/dao/FemaleRepository.java)\n\n```java\npublic interface FemaleRepository extends MongoRepository\u003cFemale,String\u003e {\n\tPage\u003cFemale\u003e findAllByCreateTimeBetweenAndNameContaining(Date createTime, Date createTime2, String name, Pageable pageable);\n\n\tPage\u003cFemale\u003e findAllByCreateTimeBefore(Date createTime, Pageable pageable);\n\n\tPage\u003cFemale\u003e findAllByCreateTimeAfter(Date createTime, Pageable pageable);\n\n\tPage\u003cFemale\u003e findAllByCreateTimeBetween(Date start, Date end, PageRequest pageRequest);\n}\n```\n\n**单元测试方法**\n\n\u003e [FemaleRepositoryTest.java](https://github.com/suveng/demo/blob/master/chapter.003/src/test/java/my/suveng/app/dao/FemaleRepositoryTest.java)\n\n```java\n\t/**\n\t * description: 添加测试数据\n\t * author: suwenguang\n\t * date: 2019-09-01\n\t */\n\t@Test\n\tpublic void addTestData() {\n\t\tfor (int i = 0; i \u003c 1000; i++) {\n\t\t\tFemale entity = new Female();\n\t\t\tentity.setName(RandomUtil.randomString(12));\n\t\t\tLocalDate now = LocalDate.now();\n\t\t\tLocalDate localDate = now.minusDays(RandomUtil.randomInt(4));\n\t\t\tentity.setCreateTime(localDate.toDate());\n\t\t\tfemaleRepository.save(entity);\n\t\t}\n\t}\n\n\t/**\n\t * description: 测试查询构造器\n\t * author: suwenguang\n\t * date: 2019-09-01\n\t */\n\tpublic void  matching(){\n\t\t//精确匹配和模糊匹配\n\t\tFemale probe = new Female();\n\t\tExampleMatcher matching = ExampleMatcher.matching()\n\t\t\t.withMatcher(\"name\", ExampleMatcher.GenericPropertyMatcher.of(ExampleMatcher.StringMatcher.CONTAINING))//模糊匹配\n\t\t\t.withIgnorePaths(\"id\")//忽略匹配id\n\t\t\t;\n\t\tPageRequest of = PageRequest.of(0, 10);\n\t\tPage\u003cFemale\u003e all = femaleRepository.findAll(Example.of(probe, matching), of);\n\t\tSystem.out.println(JSON.toJSONString(all));\n\t}\n\n\t/**\n\t * description: 测试范围查询\n\t * author: suwenguang\n\t * date: 2019-09-01\n\t */\n\t@Test\n\tpublic void findAllByCreateTimeAfter() {\n\t\tLocalDate yesteday = new LocalDate().minusDays(3);\n\t\tPageRequest of = PageRequest.of(0, 10);\n\t\tList\u003cFemale\u003e byCreateTimeAfter = femaleRepository.findAllByCreateTimeAfter(yesteday.toDate(), of);\n\t\tSystem.out.println(JSON.toJSONString(byCreateTimeAfter));\n\t}\n\n\t/**\n\t * description: 测试范围查询\n\t * author: suwenguang\n\t * date: 2019-09-01\n\t */\n\t@Test\n\tpublic void findByCreateTimeBetween() {\n\t\tLocalDate localDate = new LocalDate();\n\t\tPage\u003cFemale\u003e byCreateTimeBetween = femaleRepository.findByCreateTimeBetween(localDate.minusDays(2).toDate(), localDate.toDate(), PageRequest.of(0, 10));\n\t\tSystem.out.println(JSON.toJSONString(byCreateTimeBetween.getContent()));\n\t}\n```\n\n\n\n## 进阶Querydsl扩展复杂查询\n\n\u003e (基于单表的复杂查询,多表复杂查询暂时不纳入讨论范围)\n\n如果按照以上的用法,动态扩展多条件查询仍然不能够完美支持,会导致代码冗余,当然你如果使用mongoTemlate进行自己封装,另当别论.\n\n那么为了实现动态扩展多条件查询,我去查看对应版本的官方文档,[跳转点这里](https://docs.spring.io/spring-data/data-mongodb/docs/2.1.2.RELEASE/reference/html/#core.extensions.querydsl),看到可以集成querydsl作为扩展.\n\n### 步骤\n\n- 整合querydsl\n\n- 使用dsl\n\n### 1.整合querydsl\n\n\u003e [1.Querydsl官网](http://www.querydsl.com/)\n\u003e\n\u003e [2.querydsl集成文档](http://www.querydsl.com/static/querydsl/latest/reference/html/ch02.html#jpa_integration)\n\n**pom.xml配置引入依赖**\n\n```xml\n       \u003c!--###############复杂查询querydsl jpa################--\u003e\n        \u003cdependency\u003e\n            \u003cgroupId\u003ecom.querydsl\u003c/groupId\u003e\n            \u003cartifactId\u003equerydsl-apt\u003c/artifactId\u003e\n            \u003cversion\u003e${querydsl.version}\u003c/version\u003e\n            \u003cscope\u003eprovided\u003c/scope\u003e\n        \u003c/dependency\u003e\n\n        \u003cdependency\u003e\n            \u003cgroupId\u003ecom.querydsl\u003c/groupId\u003e\n            \u003cartifactId\u003equerydsl-jpa\u003c/artifactId\u003e\n            \u003cversion\u003e${querydsl.version}\u003c/version\u003e\n        \u003c/dependency\u003e\n\n\u003c!--        \u003cdependency\u003e--\u003e\n\u003c!--            \u003cgroupId\u003eorg.slf4j\u003c/groupId\u003e--\u003e\n\u003c!--            \u003cartifactId\u003eslf4j-log4j12\u003c/artifactId\u003e--\u003e\n\u003c!--            \u003cversion\u003e1.6.1\u003c/version\u003e--\u003e\n\u003c!--        \u003c/dependency\u003e--\u003e\n```\n\n**为什么要注释掉slf4j?**\n\n因为我的springboot项目已经引入了slf4j,没必要重复声明,自己可以通过idea的maven dependence查看是否有引入,没有则需要重新引入\n\n### 2.使用dsl\n\n- 在`dao`的`repository`中继承`QuerydslPredicateExecutor\u003cT\u003e`\n\n  ```java\n  public interface FemaleRepository extends MongoRepository\u003cFemale,String\u003e, QuerydslPredicateExecutor\u003cFemale\u003e {\n  \n  }\n  ```\n\n  \n\n- 编写单元测试[FemaleRepositoryTest.java](https://github.com/suveng/demo/blob/master/chapter.003/src/test/java/my/suveng/app/dao/FemaleRepositoryTest.java)\n\n  ```java\n  \t/**\n  \t * description: 多条件\n  \t * author: suwenguang\n  \t * date: 2019-09-01\n  \t */\n  \t@Test\n  \tpublic void querydsl() {\n  \t\tPageRequest of = PageRequest.of(0, 10);\n  \t\tQFemale female = QFemale.female;\n  \t\tBooleanExpression createTimeBetween = female.createTime.between(LocalDate.now().minusDays(2).toDate(), LocalDate.now().minusDays(1).toDate());\n  \t\tBooleanBuilder builder = new BooleanBuilder(createTimeBetween);\n  \t\tBooleanExpression contains = female.name.contains(\"3\");\n  \t\tbuilder.and(contains);\n  \t\tPage\u003cFemale\u003e all = femaleRepository.findAll(builder,of);\n  \t\tSystem.out.println(all.getTotalElements());\n  \t\tSystem.out.println(JSON.toJSONString(all.getContent()));\n  \t}\n  ```\n\n\n\n如上所示, 这样子可以**动态构造**所需要的条件,**多个范围查询也可以支持**了!!!那么对于后台的搜索数据只需要一个接口就可以了\n\n至于怎么实现,后面再继续整合 [X-admin 2.2](https://gitee.com/daniuit/X-admin)这个后端模板, 另外出一篇文章吧.\n\n\u003e 如果对上诉**代码有问题**或者有**其他的扩展性问题**,欢迎留下你的评论.\n\n\n\n## 补充\n\n- **BooleanBuilder的类图, 可以通过idea查看,因为findAll是通过父类继承下来的接口, 里面的Predicate也是一个接口,而BooleanExpression和BooleanBuilder都是实现了Predicate的;**\n  ![](https://img2018.cnblogs.com/blog/1419387/201909/1419387-20190901192816243-1084215449.png)\n\n\n\n\n","cover":"images/wallhaven-714079.jpg","link":"20190901/suveng.html","preview":"","title":"MongoDB做CURD"},{"content":"\n\n# 开源脚手架\n\n## 地址\n\nGithub\n\n## v1.0功能\n\n- springboot2.1.2\n- druid连接池配置\n- MySQL\n- mybatis\n-  fastjson\n- 统一IDE格式化代码\n- 统一日志打印\n- 全局请求id\n- 全局异常处理\n- 业务告警: 钉钉群消息告警\n\n## 依赖\n\n- [maven3](https://maven.apache.org/)\n- [JDK 1.8](http://www.matools.com/api/java8)\n- [springboot 2.1.2](https://docs.spring.io/spring-boot/docs/2.2.x/reference/html/howto.html#howto)\n- [X-admin 后台模板  2.2](https://gitee.com/daniuit/X-admin)\n- [fastJSON 序列化工具 1.2.56](https://github.com/alibaba/fastjson)\n- [Hutool 工具包 4.5.16](https://gitee.com/loolly/hutool)\n- [LogBack日志框架 1.2.3](https://logback.qos.ch/)\n- [Poi Excel导出 4.1.0](https://www.yiibai.com/apache_poi)","cover":"images/wallhaven-714079.jpg","link":"20190825/suveng.html","preview":"","title":"开源脚手架"},{"content":"\n\n\n\n# freemarker导出复杂样式的Excel\n\n## 代码地址:\n\n[gitee](https://gitee.com/suveng/demo/tree/master/chapter.002)\n\nhttps://gitee.com/suveng/demo/tree/master/chapter.002\n\n代码存放于demo下面的chapter.002目录下, 每个模块都是独立开的springboot应用,可以直接运行 application\n\n## 环境\n\n- springboot 2.1.2\n- Freemarker 2.3.28\n- JDK1.8\n\n## 步骤\n\n### 1.找到对应Excel模板\n\n我在网上找了一网站下载了一个Excel模板, [地址](https://www.6erp.cn/portfoliotype/exceltemplatedown)\n\n下载的文件是[2018库存表](https://www.6erp.cn/download/2018%e5%ba%93%e5%ad%98%e8%a1%a8?wpdmdl=3444\u0026refresh=5d6278fa5c9881566734586)\n\n![](https://img2018.cnblogs.com/blog/1419387/201908/1419387-20190825200551854-396336777.png)\n\n\n### 2.Excel模板导出为xml格式\n\n将其导出为xml格式;直接文件另存为即可\n\n![](https://img2018.cnblogs.com/blog/1419387/201908/1419387-20190825200730668-1182199891.png)\n\n删除多余的数据, 将模板变量填进去, 这个变量是需要符合 freemarker 的变量规则的;\n\n![](https://img2018.cnblogs.com/blog/1419387/201908/1419387-20190825201249119-1659346729.png)\n\n具体内容可参考[文件](https://gitee.com/suveng/demo/blob/master/chapter.002/src/main/resources/templates/2018%E5%BA%93%E5%AD%98%E8%A1%A8.xml)\n\n\n\n### 3.替换freemarker变量\n\n\n关键修改: \n\n```\n            \u003c#list products as product\u003e\n                \u003cRow\u003e\n                    \u003cCell\u003e\n                        \u003cData ss:Type=\"String\"\u003e${product.name!}\u003c/Data\u003e\n                    \u003c/Cell\u003e\n                    \u003cCell\u003e\n                        \u003cData ss:Type=\"String\"\u003e${product.number!}\u003c/Data\u003e\n                    \u003c/Cell\u003e\n                    \u003cCell\u003e\n                        \u003cData ss:Type=\"String\"\u003e${product.type!}\u003c/Data\u003e\n                    \u003c/Cell\u003e\n                    \u003cCell\u003e\n                        \u003cData ss:Type=\"String\"\u003e${product.unit!}\u003c/Data\u003e\n                    \u003c/Cell\u003e\n                    \u003cCell\u003e\n                        \u003cData ss:Type=\"String\"\u003e${product.left!}\u003c/Data\u003e\n                    \u003c/Cell\u003e\n                    \u003cCell\u003e\n                        \u003cData ss:Type=\"String\"\u003e${product.monthNumber!}\u003c/Data\u003e\n                    \u003c/Cell\u003e\n                    \u003cCell\u003e\n                        \u003cData ss:Type=\"String\"\u003e${product.in!}\u003c/Data\u003e\n                    \u003c/Cell\u003e\n                    \u003cCell\u003e\n                        \u003cData ss:Type=\"String\"\u003e${product.out!}\u003c/Data\u003e\n                    \u003c/Cell\u003e\n                    \u003cCell ss:StyleID=\"s54\"\u003e\n                        \u003cData ss:Type=\"String\"\u003e${product.date?string('yyyy/MM/dd')}\u003c/Data\u003e\n                    \u003c/Cell\u003e\n                \u003c/Row\u003e\n            \u003c/#list\u003e\n```\n\n自己可以拿到文件,对比一下.\n\n具体 freemarker 语法, 可参考 [链接](http://www.kerneler.com/freemarker2.3.23/dgui_quickstart_basics.html) \n\n### 4.编写代码,变量替换\n\n这里我使用我自己的脚手架,其实也是一个快速启动的服务端程序,使用的是springboot构建的.有兴趣可以过去看看[链接](https://gitee.com/suveng/demo/tree/master/chapter.001)\n\n这里编写web接口: 导出模板Excel\n\n这里的数据是自己模拟的,随机生成的无意义数据,使用了hutool工具包的randomUtil\n\n\u003e AppController.java\n\n```\n@Controller\npublic class AppController {\n\t@Autowired\n\tprivate Configuration configuration;\n\n\t@RequestMapping(\"/export\")\n\tpublic void export(HttpServletResponse response) throws Exception {\n\t\t//自己封装号数据实体\n\t\tArrayList\u003cProduct\u003e products = new ArrayList\u003c\u003e();\n\n\t\t//构造数据\n\t\tfor (int i = 0; i \u003c 100; i++) {\n\t\t\tProduct e = new Product();\n\t\t\te.setName(RandomUtil.randomString(5));\n\t\t\te.setNumber(RandomUtil.randomString(2));\n\t\t\te.setOut(RandomUtil.randomString(2));\n\t\t\te.setIn(RandomUtil.randomString(2));\n\t\t\te.setType(RandomUtil.randomString(5));\n\t\t\te.setUnit(RandomUtil.randomString(4));\n\t\t\te.setMonthNumber(RandomUtil.randomString(1));\n\t\t\te.setDate(new Date());\n\t\t\tproducts.add(e);\n\t\t}\n\t\tHashMap\u003cString, Object\u003e map = new HashMap\u003c\u003e();\n\t\tmap.put(\"products\", products);\n\n\t\t//构造输出流\n\t\tTemplate template = configuration.getTemplate(\"2018库存表.xml\", \"UTF-8\");\n\t\tString fileName = \"/data/files/\" + DateUtil.now() + \".xlsx\";\n\t\tFile file = new File(fileName);\n\t\tFileWriter out = new FileWriter(fileName);\n\t\t//变量替换\n\t\ttemplate.process(map, out);\n\n\t\t//将文件输出到response,返回给客户端\n\t\tFileInputStream in = new FileInputStream(file);\n\t\tbyte[] buffer = new byte[in.available()];\n\t\tin.read(buffer);\n\t\tin.close();\n\t\tresponse.reset();\n\t\tresponse.addHeader(\"Content-Disposition\", \"attachment;filename=file.xlsx\");\n\t\tServletOutputStream outputStream = response.getOutputStream();\n\t\tresponse.setContentType(\"application/octet-stream\");\n\t\toutputStream.write(buffer);\n\t\toutputStream.flush();\n\t\toutputStream.close();\n\t}\n}\n```\n\n\n\n### 5. 结果展示\n\n![](https://img2018.cnblogs.com/blog/1419387/201908/1419387-20190825202308403-1422124016.png)\n\n\n## 存在问题\n\n1. 变量替换,耗费CPU和内存并未经过测试,与POI这些组件相比到底哪个更好,这里存在疑问?\n\n这里只是用作复杂样式的Excel数据导出,并不适合用作大量数据导出.hutool工具包中和easyExcel都是针对大量数据的Excel导出做了相应的优化,有需要可以查看对应文档\n\n- [hutool](https://hutool.cn/docs/#/poi/Excel%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90-BigExcelWriter)\n\n- [easyExcel](https://github.com/alibaba/easyexcel/blob/master/quickstart.md)\n\n","cover":"images/wallhaven-714079.jpg","link":"20190824/suveng.html","preview":"","title":"freemarker导出复杂样式的Excel"},{"content":"\n\n# 分布式CAP理论\n\n来自wiki:\n\n\u003e 在[理论计算机科学](https://zh.wikipedia.org/wiki/理論計算機科學)中，**CAP定理**（CAP theorem），又被称作**布鲁尔定理**（Brewer's theorem），它指出对于一个[分布式计算系统](https://zh.wikipedia.org/wiki/分布式计算)来说，不可能同时满足以下三点：[[1\\]](https://zh.wikipedia.org/wiki/CAP定理#cite_note-Lynch-1)[[2\\]](https://zh.wikipedia.org/wiki/CAP定理#cite_note-2)\n\u003e\n\u003e - 一致性（**C**onsistency） （等同于所有节点访问同一份最新的数据副本）\n\u003e - [可用性](https://zh.wikipedia.org/wiki/可用性)（**A**vailability）（每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据）\n\u003e - [分区容错性](https://zh.wikipedia.org/w/index.php?title=网络分区\u0026action=edit\u0026redlink=1)（**P**artition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择[[3\\]](https://zh.wikipedia.org/wiki/CAP定理#cite_note-3)。）\n\u003e\n\u003e 根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项[[4\\]](https://zh.wikipedia.org/wiki/CAP定理#cite_note-4)。理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。\n\n\n\n**来自**:\n\n[![HollisChuang's Blog-Java干货集散地](http://www.hollischuang.com/wp-content/uploads/2018/10/Hollis.png)](https://www.hollischuang.com/)\n\n\u003e 2000年7月，加州大学伯克利分校的Eric Brewer教授在ACM PODC会议上提出CAP猜想。2年后，麻省理工学院的Seth Gilbert和Nancy Lynch从理论上证明了CAP。之后，CAP理论正式成为分布式计算领域的公认定理。\n\n无论你是一个系统架构师，还是一个普通开发，当你开发或者设计一个分布式系统的时候，CAP理论是无论如何也绕不过去的。本文就来介绍一下到底什么是CAP理论，如何证明CAP理论，以及CAP的权衡问题。\n\n## CAP理论概述\n\nCAP理论：一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。\n\n![Teorema-CAP-2](http://www.hollischuang.com/wp-content/uploads/2015/12/Teorema-CAP-2.png)\n\n\u003e 读者需要注意的的是，CAP理论中的CA和数据库事务中ACID的CA并完全是同一回事儿。两者之中的A都是C都是一致性(Consistency)。CAP中的A指的是可用性（Availability），而ACID中的A指的是原子性（Atomicity)，切勿混为一谈。\n\n## CAP的定义\n\n### Consistency 一致性\n\n一致性指“`all nodes see the same data at the same time`”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，所以，一致性，说的就是数据一致性。[分布式的一致性](http://www.hollischuang.com/archives/663)\n\n对于一致性，可以分为从客户端和服务端两个不同的视角。从客户端来看，一致性主要指的是多并发访问时更新过的数据如何获取的问题。从服务端来看，则是更新如何复制分布到整个系统，以保证数据最终一致。\n\n一致性是因为有并发读写才有的问题，因此在理解一致性的问题时，一定要注意结合考虑并发读写的场景。\n\n从客户端角度，多进程并发访问时，更新过的数据在不同进程如何获取的不同策略，决定了不同的一致性。\n\n**三种一致性策略**\n\n对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。\n\n如果能容忍后续的部分或者全部访问不到，则是弱一致性。\n\n如果经过一段时间后要求能访问到更新后的数据，则是最终一致性。\n\nCAP中说，不可能同时满足的这个一致性指的是强一致性。\n\n### Availability 可用性\n\n可用性指“`Reads and writes always succeed`”，即服务一直可用，而且是正常响应时间。\n\n对于一个可用性的分布式系统，每一个非故障的节点必须对每一个请求作出响应。所以，一般我们在衡量一个系统的可用性的时候，都是通过停机时间来计算的。\n\n|          可用性分类          | 可用水平（%） | 年可容忍停机时间 |\n| :--------------------------: | :-----------: | :--------------: |\n|          容错可用性          |    99.9999    |      \u003c1 min      |\n|          极高可用性          |    99.999     |      \u003c5 min      |\n| 具有故障自动恢复能力的可用性 |     99.99     |     \u003c53 min      |\n|           高可用性           |     99.9      |      \u003c8.8h       |\n|          商品可用性          |      99       |    \u003c43.8 min     |\n\n通常我们描述一个系统的可用性时，我们说淘宝的系统可用性可以达到5个9，意思就是说他的可用水平是99.999%，即全年停机时间不超过 `(1-0.99999)*365*24*60 = 5.256 min`，这是一个极高的要求。\n\n好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。一个分布式系统，上下游设计很多系统如负载均衡、WEB服务器、应用代码、数据库服务器等，任何一个节点的不稳定都可以影响可用性。\n\n### Partition Tolerance分区容错性\n\n分区容错性指“`the system continues to operate despite arbitrary message loss or failure of part of the system`”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。\n\n分区容错性和扩展性紧密相关。在分布式应用中，可能因为一些分布式的原因导致系统无法正常运转。好的分区容错性要求能够使应用虽然是一个分布式系统，而看上去却好像是在一个可以运转正常的整体。比如现在的分布式系统中有某一个或者几个机器宕掉了，其他剩下的机器还能够正常运转满足系统需求，或者是机器之间有网络异常，将分布式系统分隔未独立的几个部分，各个部分还能维持分布式系统的运作，这样就具有好的分区容错性。\n\n简单点说，就是在网络中断，消息丢失的情况下，系统如果还能正常工作，就是有比较好的分区容错性。\n\n## CAP的证明\n\n![intro_thumb](http://www.hollischuang.com/wp-content/uploads/2016/03/intro_thumb.png)\n\n如上图，是我们证明CAP的基本场景，网络中有两个节点N1和N2，可以简单的理解N1和N2分别是两台计算机，他们之间网络可以连通，N1中有一个应用程序A，和一个数据库V，N2也有一个应用程序B2和一个数据库V。现在，A和B是分布式系统的两个部分，V是分布式系统的数据存储的两个子数据库。\n\n在满足一致性的时候，N1和N2中的数据是一样的，V0=V0。在满足可用性的时候，用户不管是请求N1或者N2，都会得到立即响应。在满足分区容错性的情况下，N1和N2有任何一方宕机，或者网络不通的时候，都不会影响N1和N2彼此之间的正常运作。\n\n![scenario1_thumb](http://www.hollischuang.com/wp-content/uploads/2016/03/scenario1_thumb.png)\n\n如上图，是分布式系统正常运转的流程，用户向N1机器请求数据更新，程序A更新数据库Vo为V1，分布式系统将数据进行同步操作M，将V1同步的N2中V0，使得N2中的数据V0也更新为V1，N2中的数据再响应N2的请求。\n\n这里，可以定义N1和N2的数据库V之间的数据是否一样为一致性；外部对N1和N2的请求响应为可用行；N1和N2之间的网络环境为分区容错性。这是正常运作的场景，也是理想的场景，然而现实是残酷的，当错误发生的时候，一致性和可用性还有分区容错性，是否能同时满足，还是说要进行取舍呢？\n\n作为一个分布式系统，它和单机系统的最大区别，就在于网络，现在假设一种极端情况，N1和N2之间的网络断开了，我们要支持这种网络异常，相当于要满足分区容错性，能不能同时满足一致性和响应性呢？还是说要对他们进行取舍。\n\n![scenario2_thumb](http://www.hollischuang.com/wp-content/uploads/2016/03/scenario2_thumb.png)\n\n假设在N1和N2之间网络断开的时候，有用户向N1发送数据更新请求，那N1中的数据V0将被更新为V1，由于网络是断开的，所以分布式系统同步操作M，所以N2中的数据依旧是V0；这个时候，有用户向N2发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据V1，怎么办呢？\n\n有二种选择，第一，牺牲数据一致性，保证可用性。响应旧的数据V0给用户；\n\n第二，牺牲可用性，保证数据一致性。阻塞等待，直到网络连接恢复，数据更新操作M完成之后，再给用户响应最新的数据V1。\n\n这个过程，证明了要满足分区容错性的分布式系统，只能在一致性和可用性两者中，选择其中一个。\n\n## CAP权衡\n\n通过CAP理论及前面的证明，我们知道无法同时满足一致性、可用性和分区容错性这三个特性，那要舍弃哪个呢？\n\n我们分三种情况来阐述一下。\n\n### CA without P\n\n这种情况在分布式系统中几乎是不存在的。首先在分布式环境下，网络分区是一个自然的事实。因为分区是必然的，所以如果舍弃P，意味着要舍弃分布式系统。那也就没有必要再讨论CAP理论了。这也是为什么在前面的CAP证明中，我们以系统满足P为前提论述了无法同时满足C和A。\n\n比如我们熟知的关系型数据库，如My Sql和Oracle就是保证了可用性和数据一致性，但是他并不是个分布式系统。一旦关系型数据库要考虑主备同步、集群部署等就必须要把P也考虑进来。\n\n其实，在CAP理论中。C，A，P三者并不是平等的，CAP之父在《Spanner，真时，CAP理论》一文中写到：\n\n\u003e 如果说Spanner真有什么特别之处，那就是谷歌的广域网。Google通过建立私有网络以及强大的网络工程能力来保证P，在多年运营改进的基础上，在生产环境中可以最大程度的减少分区发生，从而实现高可用性。\n\n从Google的经验中可以得到的结论是，无法通过降低CA来提升P。要想提升系统的分区容错性，需要通过提升基础设施的稳定性来保障。\n\n所以，对于一个分布式系统来说。P是一个基本要求，CAP三者中，只能在CA两者之间做权衡，并且要想尽办法提升P。\n\n### CP without A\n\n如果一个分布式系统不要求强的可用性，即容许系统停机或者长时间无响应的话，就可以在CAP三者中保障CP而舍弃A。\n\n一个保证了CP而一个舍弃了A的分布式系统，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。\n\n设计成CP的系统其实也不少，其中最典型的就是很多分布式数据库，他们都是设计成CP的。在发生极端情况时，优先保证数据的强一致性，代价就是舍弃系统的可用性。如Redis、HBase等，还有分布式系统中常用的Zookeeper也是在CAP三者之中选择优先保证CP的。\n\n无论是像Redis、HBase这种分布式存储系统，还是像Zookeeper这种分布式协调组件。数据的一致性是他们最最基本的要求。一个连数据一致性都保证不了的分布式存储要他有何用？\n\n在我的[Zookeeper介绍（二）——Zookeeper概述](http://www.hollischuang.com/archives/1275)一文中其实介绍过zk关于CAP的思考，这里再简单回顾一下：\n\nZooKeeper是个CP（一致性+分区容错性）的，即任何时刻对ZooKeeper的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性。但是它不能保证每次服务请求的可用性，也就是在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。ZooKeeper是分布式协调服务，它的职责是保证数据在其管辖下的所有服务之间保持同步、一致。所以就不难理解为什么ZooKeeper被设计成CP而不是AP特性的了。\n\n### AP wihtout C\n\n要高可用并允许分区，则需放弃一致性。一旦网络问题发生，节点之间可能会失去联系。为了保证高可用，需要在用户访问时可以马上得到返回，则每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。\n\n这种舍弃强一致性而保证系统的分区容错性和可用性的场景和案例非常多。前面我们介绍可用性的时候说到过，很多系统在可用性方面会做很多事情来保证系统的全年可用性可以达到N个9，所以，对于很多业务系统来说，比如淘宝的购物，12306的买票。都是在可用性和一致性之间舍弃了一致性而选择可用性。\n\n你在12306买票的时候肯定遇到过这种场景，当你购买的时候提示你是有票的（但是可能实际已经没票了），你也正常的去输入验证码，下单了。但是过了一会系统提示你下单失败，余票不足。这其实就是先在可用性方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，会影响一些用户体验，但是也不至于造成用户流程的严重阻塞。\n\n但是，我们说很多网站牺牲了一致性，选择了可用性，这其实也不准确的。就比如上面的买票的例子，其实舍弃的只是强一致性。退而求其次保证了最终一致性。也就是说，虽然下单的瞬间，关于车票的库存可能存在数据不一致的情况，但是过了一段时间，还是要保证最终一致性的。\n\n对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到N个9，即保证P和A，舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。\n\n### 适合的才是最好的\n\n上面介绍了如何CAP中权衡及取舍以及典型的案例。孰优孰略，没有定论，只能根据场景定夺，适合的才是最好的。\n\n对于涉及到钱财这样不能有一丝让步的场景，C必须保证。网络发生故障宁可停止服务，这是保证CP，舍弃A。比如前几年支付宝光缆被挖断的事件，在网络出现故障的时候，支付宝就在可用性和数据一致性之间选择了数据一致性，用户感受到的是支付宝系统长时间宕机，但是其实背后是无数的工程师在恢复数据，保证数数据的一致性。\n\n对于其他场景，比较普遍的做法是选择可用性和分区容错性，舍弃强一致性，退而求其次使用最终一致性来保证数据的安全。这其实是分布式领域的另外一个理论——BASE理论。我们下一篇文章再来介绍。\n\n## 总结\n\n无论你是一个架构师，还是一个普通开发，在设计或开发分布式系统的时候，不可避免的要在CAP中做权衡。需要根据自己的系统的实际情况，选择最适合自己的方案。\n\n## 参考资料：\n\n[CAP和BASE理论](http://my.oschina.net/foodon/blog/372703)\n\n[CAP原理的证明](http://www.xiaoyaochong.net/wordpress/index.php/2013/07/27/cap原理的证明/)\n\n[一文带你重新审视CAP理论与分布式系统设计](http://dbaplus.cn/news-159-1917-1.html)\n\n## 拓展阅读：\n\n[CAP理论](http://blog.csdn.net/chen77716/article/details/30635543)","cover":"images/wallhaven-714079.jpg","link":"20190812/suveng.html","preview":"","title":"分布式CAP理论"},{"content":"\n\n# git flow工作流程\n\n这是一种以发布为中心的开发模式。该模式以荷兰程序员 [Vincent Driessen](https://links.jianshu.com/go?to=http%3A%2F%2Fnvie.com%2Fabout%2F)发表的 [A successful Git branching model](https://links.jianshu.com/go?to=http%3A%2F%2Fnvie.com%2Fposts%2Fa-successful-git-branching-model%2F)为基础，组合了 [GitHub](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com)的开发流程。\n\n![](https://oscimg.oschina.net/oscnet/48001bae12f3a3997b6916b2ae2bfc331e4.jpg)\n\n该流程以分支名表示软件开发中开发状态的迁移。\n\n1. 从开发分支（develop）创建特性分支（feature branches），进行功能的实现或修改\n2. 特性分支（feature branches）的修改结束后，与开发分支（develop）合并\n3. 重复上述 `1`和 `2`，不断实现功能直至可以发布\n4. 创建用于发布的分支（ release branches），处理发布的各项工作\n5. 发布准本工作完成后与 master 分支合并，打上版本标签（Tag）进行发布\n6. 如果发布的软件出现 BUG，以打了标签的版本为基础进行修正（hotfixs）\n\n## 导入 Git Flow 前的准本\n\n### 安装 git-flow\n\n**Mac 下的安装**\n\n```\n$ brew install git-flow\n```\n\n**Linux 下的安装**\n\n```\n$ sudo apt-get install git-flow\n```\n\n**确认运行状况**\n\n```\n$ git flow\n```\n\n### 仓库的初始设置\n\n**创建仓库**\n\n首先，在 GitHub 上新建一个 Git 仓库。这里我们创建一个附带 README.md 文件的名为 blog 的仓库。\n\n然后在本地 clone 这个仓库。\n\n```\n$ git clone git@github.com:lw1024/blog.git\n```\n\n**进行 git flow 的初始化设置**\n\n```\n$ cd blog\n$ git flow init -d\n```\n\n*注：这里的 -d参数是表示使用默认值进行设置*\n\n查看已创建的分支。\n\n```\n$ git branch -a\n* develop\n  master\n  remotes/origin/HEAD -\u003e origin/master\n  remotes/origin/master\n```\n\n此时仓库中的分支状况如上所示。\n\n**在远程仓库中也创建 develop 分支**\n\n```\n$ git push -u origin develop\n$ git branch -a\n* develop\n  master\n  remotes/origin/HEAD -\u003e origin/master\n  remotes/origin/develop\n  remotes/origin/master\n```\n\n## 模拟体验 Git Flow\n\n### master 分支与 develop 分支的区别\n\n在 Git Flow 中和两个分支至关重要，它们会贯穿整个开发流程，绝对不会被删除。\n\n**master 分支**\n\nmaster 分支始终保持着软件可以正常运行的状态。由于要维持这一状态，所以不允许开发者直接对 master 分支的代码进行修改和提交。\n\n只有在其他分支的开发工作进展到可以发布的程度后，才会合并到 master 分支中，而且这一合并只在发布成品是进行。发布时会附加包含版本编号的标签（Tag）。\n\n**develop 分支**\n\ndevelop 分支是开发过程中的代码中心分支。与 master 分支一样，这个分支也不允许开发者直接进行修改和提交。\n\n程序员要以 develop 分支为起点新建 feature 分支，在 feature 分支中进行新功能的开发或者代码的修改。\n\n### 在 feature 中进行的工作\n\n1. 从 develop 分支创建 feature 分支\n2. 在 feature 分支中实现目标功能\n3. 通过 GitHub 向 develop 分支发送 Pull Request\n4. 接受其他开发者审查后，将 Pull Request 合并至 develop 分支\n\n与 develop 分支合并后，已经完成工作的 feature 分支就可以在适当的时候删除。\n\n**创建分支**\n\n前提，我们目前在 develop 分支下\n\n```\n$ git pull\n$ git flow feature start add-user\n```\n\n现在我们已经创建并切换到了 feature/add-user 分支。\n\n**在分支中进行作业**\n\n接下来在刚刚创建的 feature/add-user 分支中实现目标功能并进行提交。\n\n### 发送 Pull Request\n\n功能实现之后，需要通过 GitHub 发送 Pull Request，请求 develop 分支合并 feature/add-user 分支的内容。*注意，这里不能与本地的 Git 仓库进行合并，而要利用 GitHub 的 Pull Request 功能接受代码审查，然后在合并到远程仓库的分支中。*\n\n首先，我们将 feature/add-user 分支 push 到 GitHub 端远程仓库。\n\n```\n$ git push origin feature/add-user\n```\n\n如果是与其他开发者共同开发同一个 feature 分支，那么远程仓库的的 add-user 分支可能已经被更新，要记得通过 pull 操作获取 add-user 分支的最新代码。另外，我们在开发这个 feature 分支的过程中，develop 分支可能有了最新版本，所以要养成在 push 之前先获取最新 develop 分支的习惯。确保上述两点之后再进行 push。\n\n如果在开发这个 feature 分支的的时候，develop 分支已经有了新版本，那可以先 merge 这个 develop 分支到这个 feature 分支。\n　　\n现在，打开 GitHub 的仓库页面，切换到 feature/add-user 分支，然后发送 Pull Request。\n\n### 通过代码审查提高代码质量\n\n发送 Pull Request 之后，通过下列步骤利用 Pull Request 从其他开发者哪里获取反馈，不断精炼代码。\n　　1. 由其他开发者进行代码审查，在 Pull Request 中提供反馈\n　　2. 修正代码以反映反馈的内容（在本地 feature/add-user 分支中）\n　　3. 将 feature/add-user 分支 push 到远程仓库（自动添加至之前的 Pull Request）\n　　4. 重复前三步\n　　5. 确认 Pull Request 没有问题后，由其他开发者将其合并至 develop 分支\n\n下面是几个反馈的要点。\n　　* 没有测试/测试未通过\n　　* 违反编码规则\n　　* 代码品质过低（命名不明确，方法冗长等）\n　　* 还有重构的余地\n　　* 有重复部分\n\n### 更新本地的 develop 分支\n\n```\n$ git checkout develop\n$ git pull\n```\n\n每当需要从 develop 分支创建 feature 等分支是，记得一定要先执行上述操作，保证 develop 分支处于最新状态。\n　　\n另外，如果本地还有其他正在开发中的 feature 分支时，可以将更新后的 develop 分支 merge 到该 feature 分支中。\n\n### 在 release 分支中进行的工作\n\n假设我们的软件已经可以发布，接下来需要给软件分配一个版本号进行发布。今后对这个版本的软件制作 BUG 修复，不再进行其他支持。如果发布所需的工作尚未全部完成，那么绝对不可以进入接下来的工作阶段。\n　　\n　　*接下来的操作，都需要发布管理员负起责任认真执行。*\n\n**创建分支**\n\n```\n$ git checkout develop\n$ git pull\n$ git flow release start '1.0.0'\n```\n\nrelease/1.0.0 分支已经成功创建，它就是这次的 release 分支。\n\n**分支内的工作**\n\n在这个分支中，我们只处理与发布相关的提交。比如版本编号变更等元数据的添加工作。如果软件部署到预演环境后经测试发现 BUG，相关的修正也要提交给这个分支。但要记住，该分支中绝对不可以包含需求变更或功能变更等重大修正。这一阶段的提交数应该限制到最低。\n\n**进行发布与合并**\n\n发布前的修正全部处理完后，我们结束这一分支\n\n```\n$ git flow release finish '1.0.0'\n```\n\n1. release 分支将合并至 master 分支。分支在合并时会询问提交信息，如果没有需要特别声明的事项，可以直接保持默认状态。\n2. 接下来，合并后的 master 分支会提示需要一个版本号，填写上我们写的即可。\n3. 随后，release 分支的状态会合并至 develop 分支。\n\n**查看版本标签**\n\n```\n$ git tag\n1.0.0\n```\n\n### 更新到远程仓库\n\n先从 develop 分支开始\n\n```\n$ git push origin develop\n```\n\n然后是 master 分支\n\n```\n$ git checkout master\n$ git push origin master\n```\n\n再 push 标签信息\n\n```\n$ git push --tags\n```\n\n### 在 hotfix 分支中进行的工作\n\nhotfix 分支都是以发布版本的标签或 master 分支为起点。借助 hotfix 分支，可以在不影响 develop 分支正常开发的情况下，有其他开发者处理 bug 修复工作。\n\n**创建分支**\n\n遇到下述情况时需要创建 hotfix 分支进行应对。\n\n- 最新的 1.0.0 版中发现了 bug 或漏洞\n- develop 分支正在开发新功能，无法面向用户进行发布\n- 漏洞需要及早处理，无法等到下一次版本发布\n\n假设修复 bug 后的版本升至 1.0.1\n\n首先，从 GitHub 端远程仓库获取 Tag 信息。\n\n```\n$ git fetch origin\n```\n\n现在以 1.0.0 为起点，创建名为 1.0.1 的 hotfix 分支。\n\n```\n$ git flow hotfix start '1.0.1' '1.0.0'\n```\n\n在这个分支中修复软件的漏洞并进行提交。\n\n等修复工作全部结束后，将 hotfix 分支 push 到 GitHub 端远程仓库，并向 master 分支发送 Pull Request。\n\n```\n$ git push origin hotfix/1.0.1\n```\n\n**创建标签和进行发布**\n\n假设发送的 Pull Request 经过了其他开发者的审查，并且已经与 master 分支合并。现在就该利用 GitHub 的功能创建 1.0.1 的标签了。\n　　\n访问 GitHub 的仓库页面，从菜单中选择 release，打开该仓库的布信息。点击 Draft a new release 按钮，再输入标签的相关信息。在 Tag version 中输入 1.0.1，在 Target 中指定 master 分支。\n　　\n现在让本地仓库再获取一次标签。\n\n```\n$ git fetch origin\n$ git tag\n1.0.0\n1.0.1\n```\n\n**从 hotfix 分支合并至 develop 分支**\n\n操作很简单，只需登录 GitHub，从 hotfix/1.0.1 分支向 develop 分支发送 Pull Request 即可。\n　　\n如果合并后 develop 分支出现了异常，切记不要在 hotfix/1.0.1 分支中进行修正。此时应该先完成 hotfix 分支与 develop 分支的合并工作，然后在 develop 分支中尽快修复相关问题。\n\n*最后记得在本地更新 master 分支和 develop 分支。*","cover":"images/wallhaven-714079.jpg","link":"20190811/suveng.html","preview":"","title":"git flow工作流程"},{"content":"\n\n# MySQL架构\n\n## 1. 逻辑架构\n\n### 1.1 逻辑架构图\n\n![逻辑架构图](https://oscimg.oschina.net/oscnet/5ba18429e607aef4dff10d2613af85d8d5c.jpg)\n\n### 1.2 架构分层\n\n#### 1.2.1 连接层\n\nMySQL 客户端连接到MySQL server都是经过这一层的, 用与处理连接,授权校验,安全.\n\n#### 1.2.2 服务层\n\n服务层是MySQL的核心服务层:\n\n1. 查询分析\n2. SQL优化\n3. 缓存机制\n4. 内建函数\n5. 触发器\n6. 视图\n7. 存储过程\n8. .....等等\n\n\n\n#### 1.2.3 存储层\n\n存储层就是 MySQL用于存放数据的处理程序--存储引擎\n\nMySQL内置的存储引擎有: \n\n- InnoDB\n- MyISAM\n- Memory\n- NDB\n- Archive \n\nMySQL5.7的默认存储引擎是InnoDB,至于关于各个存储引擎的详细会在之后的系列文章讲到\n\n\n\n","cover":"images/wallhaven-714079.jpg","link":"20190810/suveng.html","preview":"","title":"MySQL架构"},{"content":"\n\n\n\n# 声明\n\n1. 本人只写有质量的技术文章\n\n\n\n\n\n\n\n\n","cover":"images/wallhaven-714079.jpg","link":"20190809/suveng.html","preview":"","title":"声明"}]